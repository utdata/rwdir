# Military Surplus Cleaning

::: callout
This chapter is by Prof. McDonald, who uses macOS.
:::

::: callout-warning
Because of data updates, your answers may differ slightly from what is presented here.
:::

With our Billboard assignment, we went through some common data wrangling processes --- importing data, cleaning it and querying it for answers. All of our answers involved using `group_by`, `summmarize` and `arrange` (which I dub GSA) and we summarized with `n()` to count the number of rows within our groups.

For this data story we need the GSA summary trio again, but we will use math operations within our summarize functions, mainly `sum()` to add values together.

## About the story: Military surplus transfers

After the 2014 death of Michael Brown and the unrest that followed, there was widespread criticism of Ferguson, Mo. police officers for their use of military-grade weapons and vehicles. There was also heightened scrutiny to a federal program that transfers unused military equipment to local law enforcement. Many news outlets, [including NPR](https://www.npr.org/2014/09/02/342494225/mraps-and-bayonets-what-we-know-about-the-pentagons-1033-program) and [Buzzfeed News](https://www.buzzfeednews.com/article/jimdalrympleii/war-zone-in-ferguson-how-billions-in-military-weapons-ended), did stories based on data from the "1033 program" handled through the [Law Enforcement Support Office](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/). Buzzfeed News also did a [followup report](https://www.buzzfeednews.com/article/johntemplon/police-departments-military-gear-1033-program) in 2020 where reporter John Templon published his [data analysis](https://github.com/BuzzFeedNews/2020-06-leso-1033-transfers-since-ferguson), which he did using Python.

You will analyze the same dataset to see how Central Texas police agencies have used the program and write a short data drop about transfers to those agencies.

### The 1033 program

To work through this story we need to understand how this transfer program works. You can [read all about it here](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/ProgramFAQs/), but here is the gist:

In 1997, Congress approved the "1033 program" that allows the U.S. military to give "surplus" equipment that they no longer need to law enforcement agencies like city police forces. The program is run by the [Law Enforcement Support Office](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/), which is part of the Defense Logistics Agency (which handles the global defense supply chain for all the branches of the military) within the Department of Defense. (The **program** is run by the **office** inside the **agency** that is part of the **department**.)

All kinds of equipment moves between the military and these agencies, from boots and water bottles to assault rifles and cargo planes. The local agency only pays for shipping the equipment, but that shipping cost isn't listed in the data. What is in the data is the "original value" of the equipment in dollars, ***but we can't say the agency paid for it, because they didn't***.

Property falls into two categories: controlled and non-controlled. **Controlled** property "consists of military items that are provided via a conditional transfer or 'loan' basis where title remains with DoD/DLA. This includes items such as small arms/personal weapons, demilitarized vehicles and aircraft and night vision equipment. This property always remains in the LESO property book because it still belongs to and is accountable to the Department of Defense. When a local law enforcement agency no longer wants the controlled property, it must be returned to Law Enforcement Support Office for proper disposition." This is explained in the [LESO FAQ](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/ProgramFAQs.aspx#q6).

But most of the transfers to local agencies are for **non-controlled** property that can be sold to the general public, like boots and blankets. Those items are removed from the data after one year, unless it is deemed a special circumstance.

The agency releases data quarterly, but it is really a "snapshot in time" and not a complete history. Those non-controlled items transferred more than a year prior are missing, as are any controlled items returned to the feds.

### About the data

![The raw data](images/leso-raw.png)

The data comes in a spreadsheet that has a different tab for each state and territory. I've done some initial work on the original data that is beyond the scope of this class, so we'll use my copy of the data. **I will supply a link to the combined data below.**

There is no data dictionary or record layout included with the data but I have corresponded with the Defense Logistics Agency to get a decent understanding of what is included.

-   **sheet**: Which sheet the data came from. This is an artifact from the data merging script.
-   **state**: A two-letter designation for the state of the agency.
-   **agency_name**: This is the agency that got the equipment.
-   **nsn**: The National Stock Number, a special ID that identifies the item in a government supplies database.
-   **item_name**: The item transferred. Googling the names can sometimes yield more info on specific items, or you can [search by `nsn`](https://nationalstocknumber.info/) for more info.
-   **quantity**: The number of the "units" the agency received.
-   **ui**: Unit of measurement (item, kit, etc.)
-   **acquisition_value**: a cost *per unit* for the item.
-   **demil_code**: Categories (as single letter key values) that indicate how the item should be disposed of. [Full details here](https://www.dla.mil/Working-With-DLA/Federal-and-International-Cataloging/DEMIL-Coding/DEMILCodes/).
-   **demil_ic**: Also part of the disposal categorization.
-   **ship_date**: The date the item(s) were sent to the agency.
-   **station_type**: What kind of law enforcement agency made the request.

```{r leso-setup, echo=F, message=F, warning=F}
library(tidyverse)
leso_sample <- read_rds("data-raw/leso-sample.rds")
```

Here is a glimpse of a sample of the data:

```{r leso-print, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
leso_sample |>  glimpse()
```

And a look at just some of the more important columns:

```{r sample-table}
leso_sample |> 
  select(agency_name, item_name, quantity, acquisition_value)
```

Each row of data is a transfer of a particular type of item from the U.S. Department of Defense to a local law enforcement agency. The row includes the name of the item, the quantity, and the value (\$) of a single unit.

What the data doesn't have is the **total value** of the items in the shipment. If there are 5 generators as noted in the first row above and the cost of each one is \$4623.09, we have to multiply the `quantity` times the `acquisition_value` to get the total value of that equipment.

The data also doesn't have any variable indicating if an item is controlled or non-controlled, but I've corresponded with the Defense Logistics Agency to gain a pretty good understanding of how to isolate them based on the **demil**itarization codes.

These are things I learned about by talking to the agency and reading through documentation. This kind of reporting and understanding ABOUT your data is vital to avoid mistakes.

## The questions we will answer

All answers should be based on **controlled** items given to **Texas agencies** from **Jan. 1, 2010 to present**.

-   *How many total "controlled" items were transferred to Texas agencies, and what are they all worth?* We'll summarize all the controlled items only to get the total quantity and total value of everything.
-   *How many total "controlled" items did each agency get and how much was it all worth?* Which agency got the most stuff?
    -   *How about local police agencies?* I'll give you a list.
-   *What specific "controlled" items did each agency get and how much were they worth?* Now we're looking at the kinds of items.
    -   *What did local agencies get?*

You'll research some of the more interesting items the agencies received so you can include them in a short data drop.

## Getting started: Create your project

::: callout-note
If you are using posit.cloud, you'll want to refer to the [Using posit.cloud](posit-cloud.qmd) chapter to create your project, using the material below as necessary.
:::

We will build the same project structure that we did with the Billboard project. In fact, all our class projects will have this structure. Since we've done this before, some of the directions are less detailed.

1.  With RStudio open, make sure you don't have a project open. Go to *File \> Close project*.
2.  Use the create project button (or *File \> New project*) to create a new project in a **New Directory**.
3.  For the project type, choose **Quarto Website**
4.  Name the directory "yourname-military-surplus", but with your name.
5.  In the `index.qmd` file, replace the title value with "Military Surplus", as that is our project title.
6.  Remove the boilerplate stuff after the YAML title and write in Markdown a little about what this is ... a class project about surplus military equipment. You can come back to this later to flesh it out.
7.  Create two folders: `data-raw` and `data-processed`.

## Cleaning notebook

Again, like Billboard, we'll create a notebook specifically for downloading, cleaning and prepping our data.

1.  Create a new **Quarto Document**.
2.  For the title use "Cleaning".
3.  Remove the rest of the boilerplate template.
4.  Save the file and name it `01-cleaning.qmd`.
5.  Open `_quarto.yml` and change the navigation link from `about.qmd` to `01-cleaning.qmd`.

### The goals of the notebook

As noted before, I separate cleaning into a separate notebook so that each subsequent analysis notebook can take advantage of that work. It's the DRY principal in programming: Don't Repeat Yourself. Often I will be in an analysis notebook realizing that I have more cleaning to do, so I'll go back to the cleaning notebook, add it and rerun everything. Because I've worked with and researched this data, I'm aware of cleaning steps that a newcomer to the data might not be aware of at this point. To save you that time and heartache, we will take advantage of my experience and do all this cleaning work up front even though you haven't seen the "need" for it yet.

That's a long-winded opening to say let's add our notebook goals so you know what's going on here.

1.  In Markdown, add a headline noting these are notebook goals.
2.  Add the goals below:

``` txt
- Download the data
- Import the data
- Check datatypes
- Create a total_value variable
- Create a control_type variable
- Filter the date range (since Jan. 1 2010)
- Export the cleaned data
```

### Add a setup section

This is the section in the notebook where we add our libraries and such. Again, every notebook has this section, though the packages used may vary on need. This time (and each time hense) we will add some "execution options" to our setup chunk.

1.  Add a headline called "Setup" and text about what we are doing, adding our libraries.
2.  Add your setup code chunk with the code below.

```{r}
#| echo: fenced
#| label: setup
#| message: false

library(tidyverse)
```

Some reminders:

-   The `#| label: setup` is special in that it will be run first no matter where we are in the notebook. Helpful to make sure your libraries are loaded.
-   The `#| message: false` option silences the message about all the different packages in the tidyverse when the library is loaded. It just cleans up the notebook.

One other note about this ... we should only need the `tidyverse` library for this notebook because the data already has clean names (no need for `janitor`.)

## Download the data

1.  A new section means a new headline and description. Add it. It is good practice to describe and link to the data you will be using. You can use the text below:

``` txt
While the data we will use here if from Prof. McDonald, it is from the [Law Enforcement Support Office](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/). Find more information [about the program here](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/ProgramFAQs/).
```

::: callout-note
Note the text above scrolls off the screen. Use the copy icon to select all the text.
:::

1.  Use the `download.file()` function to download the date into your `data-raw` folder. Remember you need two arguments:

``` r
download.file(
  "url_to_data",
  "path_to_folder/filename.csv",
  mode = "wb"
)
```

What you need:

-   The data can be found at this url below
-   It should be saved into your `data-raw` folder with a name for the file.

``` txt
https://github.com/utdata/rwd-r-leso/blob/main/data-processed/leso.csv?raw=true
```

```{r download}
#| code-fold: true
#| code-summary: "Try writing this on your own"
#| message: false

# You can comment the lines below once you have the data
download.file(
  "https://github.com/utdata/rwd-r-leso/blob/main/data-processed/leso.csv?raw=true",
  "data-raw/leso.csv",
  mode = "wb"
)
```

Once you've built your code chunk and run it, you should make sure the file downloaded into the correct place: in your `data-raw` folder.

::: callout-note
If you get an error about the path, you might make sure you created the `data-raw` folder first.
:::

## Import the data

It's time to import the data into the notebook. Like the Billboard project, we are again working with a CSV, or comma-separated-values text file.

1.  Add a new Markdown section noting you are doing the import. Include a headline, text and a new code chunk.

I suggest you build the code chunk a bit at a time in this order:

1.  Use `read_csv()` to read the file from our `data-raw` folder.
2.  Edit that line to put the result into a tibble object using `<-`. Name your new tibble `leso`.
3.  Print the tibble as a table to the screen again by putting the tibble object on a new line and running it. This allows you to see it in columnar form.

```{r}
#| code-fold: true
#| code-summary: "Try real hard first before clicking here for the answer."
#| message: false
#| output: false

# assigning the tibble
leso <- read_csv("data-raw/leso.csv")
# printing the tibble
leso
```

The output you get will be the table, which looks sort of like this, but I'm just showing the first six lines:

```{r}
#| echo: false

leso |> head()
```

### Glimpse the data

1.  In a new code block, print the tibble but pipe it into `glimpse()` so you can see all the column names.

```{r leso-glimpse}
leso |>  glimpse()
```

## Checking datatypes

Take a look at your glimpse returns. These are the things to watch for:

-   Are your variable names (column names) clean? All lowercase with `_` separating words?
-   Are dates saved in a date format? `ship_date` looks good at `<dttm>`, which means "datetime".
-   Are your numbers really numbers? `acquisition_value` is the column we are most concerned about here, and it looks good.

This data set looks good (because I pre-prepared it for you), but you always want to check and make corrections, like we did to fix the date in the Billboard assignment.

## Remove unnecessary columns

Sometimes at this point in a project, you might not know what columns you need to keep and which you could do without. The nice thing about doing this with code in a notebook is we can always go back, make corrections and run our notebook again. In this case, we will remove the `sheet` variable since we don't need it. (It's an artifact of the processing I've done on the file.)

1.  Start a new section with a headline and text to explain you are removing unneeded columns.
2.  Add a code chunk and the following code. I'll explain it below.

```{r remove-cols}
leso_tight <- leso |> 
  select(!sheet)

leso_tight |> glimpse()
```

In English, we are:

-   creating a new tibble `leso_tight` and then ..
-   filling it with this: The `leso` data AND THEN we use select to remove the column called `sheet`. We then glimpse the new data.

Within the `select()` function, we use `!` to "negate" the column called "sheet". If we wanted to remove more than one column --- say both `sheet` and `station_type` --- then we would use `!` negate in conjunction with the `c()` function to combine items into a new vector, like this: `select(!c(sheet, station_type))`.

The use of `!` to remove things will come up in other places in R, as will using `c()` to combine things together.

So now we have a tibble called `leso_tight` that we will work with in the next section.

## Create a total_value column

During my reporting about this data I learned that the `acquisition_value` noted in the data is for a single "unit" of each item. If the shipment item was a rifle with a `quantity` of "5" and `acquisition_value` of "200", then each rifle is worth \$200, but the total shipment would be 5 times \$200, or \$1,000. That \$1000 total value is not listed in the data, so we need to add it.

Let's walk through how to do that with a different example.

When we used `mutate()` to convert the date in the Billboard assignment, we were reassigning values in each row of a column back into the same column.

In this assignment, we will use `mutate()` to create a **new** column with new values based on a calculation. Let's review the concept first.

If you started with data like this:

| item  | item_count | item_value |
|-------|-----------:|-----------:|
| Bread |          2 |        1.5 |
| Milk  |          1 |       2.75 |
| Beer  |          3 |          9 |

And then wanted to create a total value of each item in the table, you would use `mutate()`:

``` r
# Don't put this in your notebook. It's just explanation.
data |> 
  mutate(total_value = item_count * item_value)
```

You would get a return like this, with your new `total_value` column added at the end:

| item  | item_count | item_value | total_value |
|-------|-----------:|-----------:|------------:|
| Bread |          2 |        1.5 |           3 |
| Milk  |          1 |       2.75 |        2.75 |
| Beer  |          3 |          9 |          27 |

Other math operators work as well: `+`, `-`, `*` and `/`.

So, now that we've talked about how it is done, I want you to:

1.  Create a new section with headline, text and code chunk.
2.  Use `mutate()` to create a new `total_value` column that multiplies `quantity` times `acquisition_value`.
3.  Assign those results into a new tibble called `leso_total` so we can all be on the same page.
4.  Glimpse the new tibble so you can check the results.

```{r create-total-value}
#| code-fold: true
#| code-summary: "Try it on your own. You can figure it out!"

leso_total <- leso_tight |> 
  mutate(
    total_value = quantity * acquisition_value
  )

leso_total |> glimpse()
```

### Check that it worked!!

Note that new columns are added at the end of the tibble. Sometimes you can look through the glimpsed data to see if your mutate worked correctly, but that depends on the data.

If there isn't enough information visible, you might try printing out some rows of the data to peek through it.

1.  **Edit your chunk** on the last line to change `glimpse()` to `head(20)`

I'm just showing that last line here:

```{r}
leso_total |> head(20)
```

At this point you can page through the columns to check the math. But even with this, there are a lot of columns to page through. You can use add on `select()` to pluck out the columns of interest to check.

1.  **Edit** your chunk's last line like this:

```{r}
leso_total |> 
  head(20) |>
  select(agency_name, quantity, acquisition_value, total_value)
```

This should allow you to check if the math worked. As of this writing, there was a record for "ABBEVILLE POLICE DEPT" that has a `quantity` of "10" and `acquisition_value` of "15871.59" and I got a `total_value` of "158715.90". So, 10 \* 15871.59 = 158715.90, which is correct!

Something to note about this process: In the first part of this chunk we are taking `leso_tight`, making some changes to it and the **saving** it into `leso_total`. We have two objects now, one before the changes and one after.

In the last part of the chunk, we are taking `leso_total` object and we are peeking at some rows and some columns, but we are **not saving** those changes into a new object. There is no `<-` operator here. We are just printing the results to the screen so we can *see* parts of the data more clearly.

```{r}
#| include: false

# Exporting data to be used in an appendix
leso_total |> write_rds("data-processed/rwdir-leso-total.rds")
```

## Controlled vs. non-controlled

Again, by reading through the [documentation](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/) about this data I learned about controlled vs non-controlled property. Basically non-controlled generic items like boots and blankets are removed from the data after one year, but controlled items like guns and airplanes remain on the list until they are returned to the military for disposal. We are only concerned with the controlled items.

There isn't anything within the data that says it is "controlled" and really no clear indication in the documentation on how to tell what is what. So, I emailed the agency and asked them. Here is an edited version of their answer:

> Property with the DEMIL codes A and Q6 are considered non-controlled general property and fall off the LESO property books after one year. All other Demil codes are considered controlled items and stay on the LESO property book until returned to DLA for disposition/disposal. However, there are some exceptions. For instance, aircraft are always controlled regardless of the demil code. Also, LESO has the discretion to keep items as controlled despite the demil code. This happens with some high value items. There isn't a standard minimum value. It also may also depend on the type of property.

This actually took some back and forth to figure out, as I had noticed there were AIRPLANE, CARGO-TRANSPORT items in the data that were older than a year, along with some surveillance robots. That's when they replied about the airplanes, but it turns out the robots were simply an error. ***Data is dirty*** when humans get involved; somebody coded it wrong.

These "DEMIL codes" they referenced are the `demil_code` and `demil_ic` columns in the data, so we can use those to mark which records are "non-controlled" (A and Q6) and then mark all the rest as "controlled". We know of one exception -- airplanes -- which we need to mark controlled. We can't do much with the "high value" items since there isn't a specific maximum value to test. We'll just have to note that in our story, something like "the agency has discretion to designate as as controlled, such as high value items, but they are not categorized as such and may have been dropped from our analysis."

But, we can catch most of them ... we just need to work through the logic. This is not an uncommon challenge in data science, so we have some tools to do this. Our workhorse here is the `case_when()` function, where we can make decisions based on values in our data.

In the interest of time and getting this done, I will just provide the code.

```{r control-engine}
leso_control <- leso_total |> 
  mutate(
    control_type = case_when(
      str_detect(item_name, "AIRPLANE") ~ TRUE,
      (demil_code == "A" | (demil_code == "Q" & demil_ic == 6)) ~ FALSE,
      TRUE ~ TRUE
    )
  )

leso_control |> glimpse()
```

If you want to learn more about the code in that block, read the Appendix chapter titled *Using case_when*.

## Filtering our data

In the Billboard lesson you used `filter()` to get No. 1 songs and to get a date range of data. We need to do something similar here to get only data of a certain date range. We'll build the filters one at a time so we can save the resulting objects separately.

1.  Create a new section with headlines and text that denote you are filtering the data to records since Jan. 1, 2010 up to the most recent full year.
2.  Create a chunk and filter your `leso_control` data to get rows with a `ship_date` later than 2010-01-01.
3.  Save the result into a new tibble called `leso_dated`.
4.  Print out the new tibble `leso_dated`.

```{r}
#| code-fold: true
#| code-summary: "Write it yourself, but here is the code"
#| output: false

leso_dated <- leso_control |> 
  filter(
    ship_date >= "2010-01-01"
  )

leso_dated
```

### Checking the results with summary()

How do you know this date filter worked? Well, my data went from `r nrow(leso_control)` to `r nrow(leso_dated)` rows, so we did something. You might look at the results table and click over to the `ship_date` columns so you can see some of the results, but you can't be sure the top row is the oldest. We could use an `arrange()` to test that, but I have another suggestion: `summary()`.

Now, `summary()` is different than `summarize()`, which we'll do plenty of in a minute. The `summary()` function will show you some results about each column in your data, and when it is a number or date, it will give you some basic stats like min, max and median values.

1.  **Edit your chunk** to not just print out the tibble, but pipe that into `summary()`, like this:

```{r}
#| output: false
leso_dated |> summary()
```

You should be be able to look at the **Min** value of `ship_date` in the summary to make sure there are not dates before 2010. Here is what that summary looks like:

```{r}
#| echo: false
leso_dated |> summary()
```

We now have an object, `leso_dated` that has all the data since 2010. We'll export this for our next notebook.

## Export cleaned data {#leso-export}

Now that we have our data selected, mutated and filtered how we want it, we can export into `.rds` files to use in other notebooks. As you may recall from Billboard, we use the `.rds` format because it will remember data types and such.

1.  Create a new section with headline and text explaining that you are exporting the data.
2.  Do it.

The function you need is called `write_rds` and you need to give it a path/name that saves the file in the `data-processed` folder. Name the file with `01-` at the beginning so you know it came from the first notebook, and then use a short and descriptive name for the rest. No spaces. **Well-formatted, descriptive file names are important to your future self and other colleagues**.

Here is my version:

```{r export}
#| code-fold: true
#| code-summary: "The last chunk. You can do it."
leso_dated |> write_rds("data-processed/01-leso-all.rds")
```

## Render and clean up your notebook

You should Render your notebook and read it over carefully. Some things to look for:

-   Make sure you have nice headlines for each of your sections.
-   Make sure your navigation works for the Home and Cleaning pages.
-   Flesh out your `index.qmd` file to make sure the basic assignment information is there.

## Things we learned in this lesson

This chapter was similar to when we imported data for Billboard, but we did introduce a couple of new concepts:

-   [`case_when()`](https://dplyr.tidyverse.org/reference/case_when.html) allows you to categorize a new column based on logic within your data.
-   `summary()` gives you descriptive statistics about your tibble. We used it to check the "min" date, but you can also see averages (mean), max and medians.
