[
["index.html", "Reporting with Data in R About this class About the author", " Reporting with Data in R Christian McDonald 2019-02-09 About this class This collection of lessons is intended to support the class Reporting With Data, taught by me, Christian McDonald, at the School of Journalism, Moody College of Communication, University of Texas at Austin. I’m a strong proponent of Scripted Journalism, a method of committing data-centric journalism in a programatic, repeatable and transparent way. There are a myriad of programming languages that further this, including Python (pandas and Jupyter) and JavaScript (Observable), but we’ll be using R, RMarkdown and RStudio. R is a super powerful, open-source programming language for data that is deep with features and an awesome communinity of users who build upon it. No matter the challenge before you in your data storytelling, there is probably a package available to help you solve that challenge. Probably more than one. There is always more than one way to do things in R. This course is an opinionated collection of lessons intended to teach students new to R and programming for the expressed act of committing journalism. As a beginner course, I strive to make it as simple as possible, which means I may not go into detail about alternative (and possibly better) ways to accomplish tasks. About the author I’m a career journalist who most recently served as Data and Projects Editor at the Austin American-Statesman before coming to the University of Texas at Austin full-time in Fall 2018. I’ve taught data-related course at UT since 2013. UT Github: utdata Github: critmcdonald Twitter: crit Email: christian.mcdonald@utexas.edu "],
["install.html", "Chapter 1 Install Party 1.1 Installing R 1.2 Installing RStudio 1.3 Install Visual Studio Code 1.4 Class project folder", " Chapter 1 Install Party Let’s get this party started. NOTE: R and RStudio are already installed on lab computers. 1.1 Installing R Our first task is to install the R programming language onto your computer. There are a number of “mirrors” which have the software. Go to the download site. Go down to USA and choose one of the links there. They should all work the same. Click on the link for your operating system. The following steps will differ slightly based on your operating system. For Macs, you want the “latest package” For Windows, you want the “base” package. You’ll need to decide whether you want the 32- or 64-bit version. (Unless you’ve got a pretty old system, chances are you’ll want 64-bit.) Here’s hoping it will be self explanatory after that. 1.2 Installing RStudio RStudio is an “integrated development environment” – or IDE – for programming in R. Basically, it’s the program you will use when doing work for this class. Go to https://www.rstudio.com and find the “Download RStudio” button. Find the “Free” versions and find the installer for your operating system and download it. Install it. Should be like installing any other program. 1.3 Install Visual Studio Code Some csv files are really big, and RStudio has a problem viewing them. A good code editor is able to look at this files and allow you to edit them. It’s a good tool to have in your arsenal. Go to the Visual Studio Code website and download the version for your operating system. 1.4 Class project folder To keep things consistent and help with troubleshooting, I’d like you to save your work in the same location all the time. On both Mac and Windows, every user has a “Documents” folder. Open that folder. (If you don’t know where it is, ask me to help you find it.) Create a new folder called “rwd”. Use all lowercase letters. When we create new “Projects”, I want you to always save them in the Documents/rwd folder. "],
["intro.html", "Chapter 2 Introduction to R 2.1 RStudio tour 2.2 Updating preferences 2.3 Starting a new Project 2.4 Using R Notebooks 2.5 Turning in our projects", " Chapter 2 Introduction to R 2.1 RStudio tour When you launch RStudio, you’ll get a screen that looks like this: Rstudio launch screen 2.2 Updating preferences There is a preference in RStudio that I would like you to change. By default, the program wants to save a the state of your work (all the variables and such) when you close a project, but that is not good practice. We’ll change that. Go to the RStudio menu and choose Preferences Under the General tab, uncheck the first four boxes. On the option “Save Workspace to .Rdata on exit”, change that to Never. Click OK to close the box. 2.3 Starting a new Project When we work in RStudio, we will create “Projects” to hold all the files related to one another. This sets the “working directory”, which is a sort of home base for the project. Click on the second button that has a green +R sign. That brings up a box to create the project with several options. You want New Directory (unless you already have a Project directory, which you don’t for this.) For Project Type, choose New Project. Next, for the Directory name, choose a new name for your project folder. For this project, use “firstname-first-project” but use YOUR firstname. I want you to be anal about naming your folders. It’s a good programming habit. Use lowercase characters. Don’t use spaces. Use dashes. For this class, start with your first name. Rstudio project name, directory When you hit Create Project, your RStudio window will refresh and you’ll see the yourfirstname-first-project.Rproj file in your Files list. 2.4 Using R Notebooks For this class, we will almost always use R Notebooks. This format allows us to write text in between our blocks of code. The text is written in a language called R Markdown, a juiced-up version of the common documentation syntax used by programmers, Markdown. It’s not hard to learn. Here’s a Markdown guide. 2.4.1 Create your first notebook Click on the button at the top-left of RStudio that has just the green + sign. Choose the item R Notebook. This will open a new file with some boilerplate R Markdown code. At the top between the --- marks, is the metadata. This is written using YAML, and what is inside are commands for the R Notebook. Don’t sweat the YAML syntax too much right now, as we won’t be editing it often. Next, you’ll see a couple of paragraphs of text that describes how to use an R Notebooks. It is written in R Markdown, and has some inline links and bold commands, which you will learn, Then you will see an R code chunk that looks like the figure below. R code chunk Let’s take a closer look at this: The three back tick characters ( found at the top left on your keyboard) followed by the {r} indicate that this is a chunk of R code. The last three back ticks say the code chunk is over. The {r} bit can have some parameters added to it. We’ll get into that later. The line plot(cars) is R programming code. We’ll see what those commands do in a bit. The green right-arrow to the far right is a play button to run the code that is inside the chunk. The green down-arrow and bar to the left of that runs all the code in the Notebook up to that point. 2.4.2 Save the .Rmd file Do command-s or hit the floppy disk icon to save the file. It will ask you what you want to name this file. Call it 01-first-file.Rmd. When you do this, you may see another new file created in your Files directory. It’s the pretty version of the notebook which we’ll see in a minute. In the metadata portion of the file, give your notebook a better title. Replace “R Notebook” in the title: &quot;R Notebook&quot; code to be “Christian’s first notebook”, but use your name. 2.4.3 Run the notebook There is only one chunk to run in this notebook, so: Click on the green right-arrow to run the code. You should get something like this: Cars plot What you’ve done here is create a plot chart of a piece of sample data that is already inside R. (FWIW, It is the speed of cars and the distances taken to stop. Note that the data were recorded in the 1920s.) But that wasn’t a whole lot of code to see there is a relationship with speed vs stopping distance, eh? 2.4.4 Adding new code chunks The text after the chart describes how to insert a new code chunk. Let’s do that. Add a return after the paragraph of text about code chunks, but before the next bit about previews. Use the keys Cmd+Option+I to add the chunk. Your cursor will be inserted into the middle of the chunk. Type in this code in the space provided: # update 52 to your age age = 52 (age - 7) * 2 Change for “52” to your real age. With your cursor somewhere in the code block, use the key command Cmd+Shift+Return, which is the key command to RUN ALL LINES of code chunk. NOTE: To run an individual line, use Cmd+Return while on that line. Congratulations! The answer given at the bottom of that code chunk is the socially-acceptable maximum age of anyone you should date. Throwing aside whether the formula is sound, let’s break down the code. # update 52 to your age is a comment. It’s a way to explain what is happening in the code without being considered part of the code. age = 52 is assigning a number (52) to a variable name (age). A variable is a placeholder. It can hold numbers, text or even groups of numbers. They are key to programming because they allow you to change the value of the variable as you go along. The next part is simple math: (age - 7) * 2 takes the value of age and subtracts 7, then multiplies by 2. When you run it, you get [1] 90. That means there was one observation, and the value was “90”. For the record, my wife is much younger than that. Now you can play with the age variable assignment to test out different ages. 2.4.5 Practice adding code chunks Now, on your own, add a similar code chunk that calculates the minimum age of someone you should date, but using the formula (age / 2) + 7. Add a comment in the code that explains what it is for. 2.4.6 Preview the report The rest of the boilerplate text here describes how you can Preview and Knit a notebook. Let’s do that now. Press Cmd+Shift+K to open a Preview. This will open a new window and show you the “pretty” notebook that we are building. Preview is a little different than Knit, which runs all the code, then creates the new knitted HTML document. It’s Knit to HMTL that you’ll want to do before turning in your assignments. 2.4.7 The toolbar One last thing to point out before we turn this in: The toolbar that runs across the top of the R Notebook file window. The image below explains some of the more useful tools, but you REALLY should learn and use keyboard commands when they are available. R Notebook toolbar 2.4.8 Knit the final workbook Save your File with Cmd+S. Use the Knit button in the toolbar to choose Knit to HTML. 2.5 Turning in our projects If you now look in your Files pane, you’ll see you have four files in our project. (Note the only one you actually edited was the .Rmd file.) Files list The best way to turn in all of those files into Canvas is to compress them into a single .zip file that you can upload to the assignment. In your computer’s Finder, open the Documents/rwd folder. Follow the directions for your operating system linked below to create a compressed version of your yourname-final-project folder. Compress files on a Mac. Compress flies on Windows. Upload the resulting .zip file to the assignment for this week in Canvas. Here is what the compression steps looks like on a Mac: Compress file: Mac If you find you make changes to your R files after you’ve zipped your folder, you’ll need to delete the zip file and do it again. Because we are building “repeatable” code, I’ll be able to download your .zip files, uncompress them, and the re-run them to get the same results. Well done! You’ve completed the first level and earned the Beginner badge. "],
["import.html", "Chapter 3 Importing data 3.1 Goals of this section 3.2 Data types 3.3 Create a new project 3.4 Let’s get some data 3.5 Import csv 3.6 Turn in your project 3.7 Resources", " Chapter 3 Importing data 3.1 Goals of this section Learn a little about data types available to R. Practice organized project setup. Learn about R packages, how to install and import them. Learn how to import CSV files. Introduce the Data Frame/Tibble. We are going to do this through working with well drilling reports from the Texas Water Development board. We’ll pull reports from counties in the Austin MSA and be able to see the kinds of wells dug, where they are the pace of drilling. 3.2 Data types After installing and launching RStudio, the next trick is to import data. Depending on the data source, this can be brilliantly easy or a pain in the rear. It all depends on how well-formatted is the data. In this class, we will primarily be importing Excel files, CSVs (Comma Separated Value) and APIs (Application Programming Interface). CSVs are a kind of lowest-common-denominator for data. Most any database or program can import or export them. Excel files are good, but are often messy because humans get involved. There are often multiple header rows, columns used in multiple ways, notes added, etc. Just know you might have to clean them up before using them. APIs are systems designed to respond to programming. In the data world, we often use the APIs by writing a query to ask a system to return a selection of data. By definition, the data is well structured. You can often determine the file type of the output as part of the API call, including … JSON (or JavaScript Object Notation) is the data format preferred by JavaScript. R can read it, too. It is often the output format of APIs, and prevalent enough that you need to understand how it works. We’ll get into it more later. Don’t get me wrong … there are plenty of other data types and connections available through R, but those are the ones we’ll deal with most in the class. 3.2.1 What is clean data The Checking Your Data section of this DataCamp tutorial has a good outline of what makes good data, but in general it should: Have a single header row with well-formed column names. Once column name for each column. No merged cells. Short names are better than long ones. Space are bad. Use and _ or . between words. Remove notes or comments from the files. Each column should have the same kind of data: numbers vs words, etc. Each row should be an In our first lesson, we’ll be using a CSV file that has several rows of description at the top. We’ll be able to skip those description lines when we import. 3.3 Create a new project We did this in our first lesson, but here are the basic steps: Launch RStudio Use the +R button to create a New Project in a New Directory Name the project yourfirstname-wells and put it in your ~/Documents/rwd folder. Use the + button to use R Notebook to start a new notebook. Change the title to “Wells drilled in Austin MSA”. Delete the other boilerplate text. Save the file as 01-wells-import.Rmd. 3.3.1 The R Package environment We have to back up from the step-by-step nature of this lesson and talk a little about the R programming language. R is an open-source language, which means that other programmers can contribute to how it works. It is what makes R beautiful. What happens is developers will find it difficult to do a certain task, so they will write an R “Package” of code that helps them with that task. They share that code with the community, and suddenly the R garage has an “ultimate set of tools”&quot; that would make Spicoli’s dad proud. One set of these packages is Hadley Wickham’s Tidyverse, a set of packages for data science. These are the tools we will use most in this course. While not required reading, I highly recommend Wickham’s book R for data science, which is free. We’ll use some of Wickham’s lectures in the course. 3.3.2 Installing and using packages There are two steps to using an R package: Install the package using install.packages(&quot;package_name&quot;). You only have to do this once, so I usually do it using the R Console instead of a script. Include the library using library(package_name). This has to be done for each Notebook or script that uses it, so it is usually one of the first things. We’re going to install several packages we will use in the Wells project. To do this, we are going to use the Console, which we haven’t talked about much. The Console and Terminal Use the image above to orient yourself to the R Console and Terminal. In the console, type in install.packages(&quot;tidyverse&quot;) and hit return. You’ll a bunch of commands work through your Console. Remember that you only have to install a package to your computer once. We’ll need another package, so also do: install.packages(&quot;janitor&quot;) We’ll use some commands from janitor to clean up our data column names. 3.3.3 Load the libraries Next, we’re going to tell our R Notebook to use these two libraries. After the metadata at the top of your notebook, use Cmd+option+i to insert an R code chunk. In that chunk, type in the two libraries and run the code block with Cmd+shift+Return. It will look like this: Libraries imported 3.4 Let’s get some data I could’ve supplied you with the raw data, but it is not hard to find and grab yourself, so let’s do that. Because I want you to teach you good data project skills, I want you first to make a folder to store your raw data. It’s good practice to separate your raw data from any other output or data. It make it easy for others to find, and can help you avoid overwriting that raw data, which should remain a pristine copy. In the Files pane, use the New Folder button to create a folder called data-raw. (I typically make a data-out or similar folder for any files that I create.) In a web browser, go to the Texas Water Development Board Driller Reports page and then click on the Well Reports Search by County and Use link. In the County drop down, choose: Bastrop, Caldwell, Hays, Travis and Williamson counties. In the Proposed Use column, choose **Select All*. Click View Reports. You get 400+ returns. Look for the floppy disk/arrow icon that is the download button. Choose CSV (comma delimited). That file should end up in your Downloads folder. Use your finder to move this into your project folder in the data-raw folder you created. This document has some descriptions of fields we may need later. 3.4.1 Inspect the data We want to look at the data so we understand it. In the Files pane, click on the data-raw folder to open in. Click on the WellsRpts_County_Use.csv file until you get the drop down that says View Files. View file When you choose that, you’ll get a warning that it is a big file. It should open it just fine, into a new window. It will look like this: Wells file The numbers on the left are row numbers in the file. Because lines will wrap in your window, those numbers let you know where each line starts. Note that the real header for this file starts as line 5, which means when we import this file, we need to skip the first four lines. You can close this file now. 3.5 Import csv Now we need to start adding some text to indicate what we are doing, which right now we are importing the file. So, write some text in Markdown that describes where the data came from and what it is. Write where the data came from. Include the link to the web page. Include which counties were included, and which After your descriptions, add a new code chunk (Cmd+option+i). Inside the chuck, add the following and hit return, then I’ll explain: wells_raw &lt;- read_csv(&quot;data-raw/WellRpts_County_Use.csv&quot;) wells_raw wells_raw is the data frame we are creating. It is the object that holds our data. We can call the variable whatever we want, but you should always use words that make sense. They can’t have spaces, which is why we are using the underscore _ character between words. &lt;- is the operator that says we are putting the stuff on the right (our data) into the variable. It’s like we are pointing the stuff from the right into the left. read_csv is the function we are using the load the data. This version from the readr package in the tidyverse is different from read.csv that comes with R. It is mo betta. Inside the parenthesis is the path to our data, inside quotes. If you start typing in that path and hit tab, it will complete the path. (Easier to show than explain). The last line is printing out the data frame, which is a bit of a trash fire at the moment. What went wrong? Remember that our data doesn’t really start until line five. We need to modify our import to skip the first for lines. But how does we find out how to do that? Help is on the way!! 3.5.1 Help files Another tab over by your Files pane is the Help pane. Click on the Help pane In the search box, type in read_csv and hit Return. What you get in return is information about that function. Any function loaded into RStudio also comes with these help files. The documentation style might look foreign at first, but you’ll get used to reading them. If we look through this one, we can see there is a skip = x option we can add to our import to skip lines. Modify the import line to this and then rerun the entire chunk with Cmd+shift+Return: wells_raw &lt;- read_csv(&quot;data-raw/WellRpts_County_Use.csv&quot;, skip = 3) I first tried skip = 4, but then it didn’t properly use the header row, perhaps because the readr package skips empty rows by default. Because there are two types of output in this code chunk, the notebook returns two square icons to choose between them. The first result shows what columns were imported and the data types. It’s important to review these to make sure things happened the way that you want. Some things to watch for: Are numbers actually numbers or characters? Have integers been imported as double numbers or vice verse? Are there numbers that should be strings, like ZIP codes? Are dates imported properly? The second result prints out the data like a table. The data object is called a Tibble, which is a fancy version of a data frame that is part of the tidyverse. I will often call a tibble a “data frame”, which is the generic R from of this data structure. Think of data frames and tibbles like a well-structured table in a spreadsheet. They are organized rows of data with columns where every item in the column is of the same data type. In short, it is our data. Take a look at the columns and inspect them. Note the column type is listed there. Are they all correct? In text below the table, write out a list of all the things you might have to fix in this data frame. We’ll fix them in the next lesson, as well as start looking more closely at the data. 3.6 Turn in your project Congratulations! You have created a new project in R and imported data. That is a feat in itself, so we will turn in this in. Save your .Rmd file. Use the Preview/Knit button to Knit your report to HTML. Look your report over and make sure you like it. If you need to, edit your .Rmd file, save, reKnit. When you are ready, go under the File menu to Close project. Go into your computers finder and locate your firstnanme-wells project. Create a .zip file of the folder Upload it to the Assignment in Canvas. 3.7 Resources This DataCamp tutorial on imports covers a ton of different data types and connections. "],
["columns.html", "Chapter 4 Columns 4.1 Goals of this lesson 4.2 Relaunch the Wells project 4.3 Clean up column names 4.4 Export the data", " Chapter 4 Columns 4.1 Goals of this lesson Use the janitor plugin to clean columns names Mass rename columns with a pattern match Rename individual columns Fix data columns and other data types 4.2 Relaunch the Wells project Launch RStudio. It might open to your last project, but I tried to turn that off in preferences our first day. Hollar if that happens. Open your Wells project. There are several ways you can accomplish this: If you’ve had the project open before, you can use the drop down in the top-right of RStudio to see a list of recent projects, and choose it from there. Or, under the File menu to Recent projects and choose it. Or, under File you can use Open Project… and go to that folder and choose it. Use the Run button in the R Notebook toolbar to Run All of the chunks, which will load all your data and load the data frame from our last assignment. 4.3 Clean up column names I’m a bit anal about cleaning up column names in my data frames, because it makes them easier to work with. We’ll use a function called clean_names from the “janitor” package to fix them. After your list of things to fix, write a Markdown headline ## Clean column names. Using the ## makes this a smaller headline than the title. The more ### the smaller the headline. The idea is to use these to organize your code and thoughts. Explain in text that we’ll use janitor to clean the column names. Insert a new code chunk (Cmd+shift+i should be second nature by now.) Insert the name of your wells_raw data frame and run it to inspect the column names again. These are not too bad, but they are a mix of upper and lowercase names, and some of them are rather long. We’ll try the janitor clean_names function first. Wrap the data frame name in the clean_names function like this, then rerun it: clean_names(wells_raw) And you’ll get a result like this: Columns cleaned with janitor Now, we haven’t actually changed the names yet, we just printed it to the screen with new names. We have to assign those changes to the same data frame, or a new one, to make them stay. Let’s assign them to a NEW data frame called wells, so we can keep the raw version around to compare. Update that same chunk of code to assign the clean names to a new data frame called wells. Then print wells to the screen so you can see the changes. Like this: wells &lt;- clean_names(wells_raw) wells It looks the same, but now it is saved as wells. This is a start. We still have some problems: Some long names, like “well_report_tracking_number2”. We have an annoying trailing “2” at the end of all the column names. Let’s remove the trailing “2” first. 4.3.1 Mass renaming of columns We can access all the column names of a data frame with a generic R function called names, and we can use a pattern matching replacement called sub() to change them. I admit, I had no idea how to do this, so I Googled “tidyverse remove a character from a column name” and found this link. It was NOT the first result … I had to look through several answers AND THAT IS PART OF LEARNING. Googling is probably the most important skill for a programmer. Write in text that we are going to change the names of all the columns to remove the “2”. Create a new code block and insert this: names(wells) What we get in return is a list of all the names of our data frames. Cool, that means we can reassign them with new values. Update that code chunk to this: names(wells) &lt;- sub(&quot;*2&quot;, &quot;&quot;, names(wells)) wells Run it, see the magic and then I’ll explain: The first names(wells) refers to the column “names” of wells, and the &lt;- indicates are will assign new names. The sub() function has three parts: The first set of quotes is what we are searching for: &quot;*2&quot;. The * is a wildcard meaning any number of any characters until we find a “2”. This is a pattern matching technique called Regular Expressions that we will learn more about later. The next set of quotes is what we are replacing our match with. Since we don’t want to keep the “2”, we replace it with an empty string. The last bit is what we are searching through. We are searching through the column names of wells, hence names(wells). So in short, we are substituting the “names” in wells with the existing names in wells, but replacing the “2” with nothing. Perhaps this is complicated for so early in this course, but it is a powerful intro into Regular Expressions that we’ll cover in more detail later. 4.3.2 Renaming individual columns Renaming individual columns is a lot less complicated, and it allows us to introduce the concept of “piping” the results of one command into another, a core component of the tidyverse. Add text that we are going to rename two columns: well_report_tracking_number and plugging_report_tracking_number. Add a new code chunk and print the wells data frame. Go back into that code chunk and add the following: wells %&gt;% rename(well_number = well_report_tracking_number) We will use the %&gt;% pipe command a lot, so it is worth knowing that the keyboard command Cmd+shift+m will give you that string. Now, I didn’t invent this keyboard command, but you might remember that Professor McDonald taught it to you. It will serve you well. Think of the %&gt;% command as “Then”. We have wells, THEN we are renaming the column. Do Cmd+Return to run that line, and you’ll see the changed column name. Note that is ONE line of code, even though it is written in multiple lines. You’ll find that we will be piping multiple commands together like this as we learn more about the tidyverse. Have you figured out how the the rename function works? rename(new_column_name = old_column_name)` It seems backward to me, but it works. Assignments in R seem to work from-right-to-left, sort of like &lt;-. Now, let’s edit this to change the other column as well. plugging_report_tracking_number is the last column of the data and super long, so let’s change that, too. We can do it in the same command. In the same code chunk, add a comma and a return before the ending ). add the new column mapping, like this: wells %&gt;% rename(well_number = well_report_tracking_number, plug_number = plugging_report_tracking_number) Note the indents there. RStudio probably indented it properly for you, but it’s done that way so you can visually see that these are related. One last thing here: Like the clean_names function (and unlike names), we haven’t actually saved these changes, we’ve only printed them to the screen. To save the change, we need to assign it back to wells, then we can print the saved data frame out again: wells &lt;- wells %&gt;% rename(well_number = well_report_tracking_number, plug_number = plugging_report_tracking_number) wells 4.3.3 Fix dates, lubridate and mutate Fixing dates in generic R can be a semi-complicated process. Luckily, there is a library within the tidyverse called lubridate that makes date conversions simple. The package was included when we installed the tidyverse package, but we need to add the library. Go back to the top of your R Notebook where the libraries are loaded, and add this line and run it: library(lubridate). Return back to the bottom of the Notebook and add text in Markdown describing that you will use lubridate to convert the date fields. Insert a new code chunk and add and run this, then I’ll explain it: wells %&gt;% mutate(drilling_start_date = mdy(drilling_start_date)) wells The first wells means we are starting with that data frame. mutate() is a conversion tool, and not just for dates. We will use this command to change and create all kinds of changes. The first argument of mutate is the name of the new column. In this case, we are changing the existing column, so we are using drilling_start_date. = is the assignment operators. What is on the right will be put into the left. mdy(drilling_start_date) is the lubridate function. We are telling lubridate that the existing format of the field that we want to be a date is in Month/Day/Year format. Lubridate is smart enough to realize the / separates the dates, and it would also understand if the separators were - or .. 4.3.3.1 Your turn It’s time for you to use some of the skills you’ve learned already to accomplish a couple of easy tasks: Update the mutate() function above to also update drilling_end_date field to a date. Hint: mutate is a tidyverse function just like rename, so it works similarly. Assign the changes you’ve made back to the wells dataframe and then reprint it to make sure it’s all good. 4.3.4 Fix the bore hole depth If you look at the CSV data, the borehole_depth is and integer (a number without a decimal point), but it was imported as a &lt;dbl&gt; number with decimals. This could cause us problems later if we wanted to math on these, so we’ll convert this to an integer using mutate(). Add a Markdown headline and description to describe our actions. Add a code chunk and add the following and run it: wells %&gt;% mutate(borehole_depth = as.integer(borehole_depth)) wells This will reassign that column as an integer. How did I know to use as.integer? I Googled “r convert float to integer” and found this tutorial and this Stack Overflow article. A side note about this: I didn’t realize this might be a problem until a later lesson. If I found a problem like this in Excel, I would have to redo all my steps, but since I’m using a script, I was able to make this change and then rerun the notebook. As a last step, we have to reassign our mutated data frame back to wells, so change the first line to wells &lt;- wells %&gt;%. 4.4 Export the data It’s not a bad idea to organize a project into multiple R Notebooks. I’ll often create my first notebook to complete the tasks of downloading and cleaning up data, and then create a new one to handle analysis, etc. (This is why I had you name the files 01-wells.Rmd.) It’s possible to output the data frame you have created with all the changes and datatypes into a special .rds format that will reimport into R in exactly the same form. We’ll do that now. Use the Files pane to create a New Folder called data-out. Create a new text header and text description to explain that you are exporting the data. (If the folder doesn’t exist already, you’ll get an error trying save the file.) Create a new code chunk and add the following and run it: saveRDS(wells, &quot;data-out/wells_01.rds&quot;) saveRDS() is the function. The first argument is the data frame you are exporting. The second argument is the path. Use your Files pane to make sure it worked. Congratulations! You finished this chapter, having renamed columns and changed data types. Depending on where we are in the week, you may be asked to turn this in at this stage. In any event, you should save and Knit your files. "],
["transform.html", "Chapter 5 Transform 5.1 Start a new R Notebook 5.2 Import our data 5.3 Goals 5.4 Filter() 5.5 Combining filters 5.6 Arrange() 5.7 Multi-step operations 5.8 Select() 5.9 Mutate() 5.10 Summarize() 5.11 Group_by() 5.12 Transform review 5.13 Turn in your project", " Chapter 5 Transform One of the packages within the tidyverse is dplyr ( cheatsheet ) which allows us to transform our data frames in ways that let us explore the data and prepare it for visualizing. It’s the R equivalent of common Excel functions like sort, filter and pivoting. dplyr functions (Some slides included here are used with permission from Hadley and Charlotte Wickham.) 5.1 Start a new R Notebook As I explained at the end of our last lesson, it’s a good practice to separate your import/cleaning functions from your analysis functions into separate notebooks, so we’ll create a new one for our analysis. Launch RStudio and open your wells project. Create a new R Notebook and set a new title of “Wells exploration and analysis”. Remove the boilerplate language and add a description of our goals: To explore an analyze our wells project. Mention that you have to run the other notebook first in case your someone else (or your future self) comes here first. Save your file as 02-wells-explore.Rmd. Insert a new chunk, load the tidyverse library and run it. Make one change to this, in that we want to start naming all our chunks. {r setup} library(tidyverse) wells &lt;- readRDS(&quot;data-out/wells_02.rds&quot;) By adding the word setup after our the {r} at the beginning, then we can find that chunk in our navigation drop down at the bottom of the R Notebook window. R Notebook navigation 5.2 Import our data Add a Markdown headline and description that you are loading the data. Add a code chunk named import with the following: Wells data imported Now we are back to where we eneded with the first notebook. 5.3 Goals What do we want to learn about these wells? Look over the columns and some of the values in them and come up with a list of at least five things to look at. Add a Markdown headline ## Goals. Create a bullet list of things you might want to find. Use a * or - to start each new line. We’ll review some of your ideas in class. 5.4 Filter() Let’s filter all the wells to the those just in Travis County. We’ll use dplyr’s filter() function to this this. It works like this: dplyr filter function Let’s filter our wells data to just those in Travis County: Travis wells When you run this, you’ll see that you the about 9000 rows instead of the 18,000+ of the full data set. Note the two equals signs there ==. It’s important two use two of them, as a single = will not work, as that means something else. There are a number of these logical test operations: dplyr logical tests 5.4.1 Filter your turn Create new code blocks and filter for the following: Wells with a proposed use of Irrigation. Wells at least 1000 feet deep. One more that might help you answer one of your goals you listed above. 5.4.2 Common mistakes with filter Common filtering mistakes 5.5 Combining filters You can filter for more than one thing at a time by separating more than one test with a comma. filter(wells, county == &quot;Travis&quot;, proposed_use == &quot;Irrigation&quot;) If you use a comma to separate tests, then both tests have to be true. If you want OR, then you use a pipe | (the shift-key above the backslash.) Boolean operators 5.5.1 Your turn combining filters Your quest is to filter to wells in Travis or Williamson counties that have a start date in 2018. BIG HINT: If you include library(lubridate) in your notebook then you can access the year of a field with year(name_of_date_field). 5.5.2 Common mistakes with combining filters Common mistakes combining Note if you want to combine a series of strings in your filter, you have to put them inside a “concatenate” function, which is shoretened to c(), as in the example above. 5.6 Arrange() The arrange() function sorts data. Sort with arrange() Let’s sort our data by their depth: arrange(wells, borehole_depth) You’ll have to scroll the colums over to see it, and the depths start at zero, which is not very sexy. As journalists, we usually want to see the largest (or deepest) thing, so we can arrange the column in descending order with this: Deepest wells Now we see some deep wells … 3300 feet when I pulled my test data. 5.7 Multi-step operations But what if you want to both filter and arrange? It is possible to nest such operations, but there is a better way: the pipe. Piping functions Two things to think of with the pipe %&gt;%. Think of it as “and then to this”. The keyboard command Cmd+Shift+m (Mac) or Ctrl+Shift+m (Windows) will give you the pipe. Need to remember that key command? While I didn’t invent the pipe, you might remember that Professor McDonald taught it to you. Let’s find the deepest well in Travis County: wells %&gt;% filter(county == &quot;Travis&quot;) %&gt;% arrange(desc(borehole_depth)) All the tidyverse functions understand the pipe, and we’ll be using it alot. It makes it easier to write and understand the code. Another advantage you’ll see is you can use tab completion in more places when you use pipes. RStudio better understands the fields you are working with when you declare the data frame first. 5.7.1 Your turn to combine and pipe Find a list of the deepest irrigation wells in Travis County in 2017. Use the pipe to string together your functions. 5.8 Select() As we’ve worked with borehole_depth it’s been kind of a pain to tab through all the fields to see the result we want. The select() function allows you to choose which fields to display from a data frame. If we are only interested in the owner and borehole_depth from our previous query of deepest wells in Travis, then we we can pipe the results to a select function. It works by listing the column names inside the function. You can use - before a column name to remove it. Add this to the end of your previous code chunk: &lt;code chunk&gt; %&gt;% select(owner_name, borehole_depth) The order of all these operations matter. If you use select to remove a column, you cannot filter using that column later. 5.9 Mutate() The mutate function allows us to change data based on a formula. We can assign the change back to an existing column or create a new one. Create columns with mutate() In the example above: gapminder is the source data frame. gdp is the new column being created. it comes first. = gdpPercap * pop is the function. It is multiplying the the two columns that are in the gapminder data frame. The applied function doesn’t have to be math. It could be pulling part of a string or any number of things. We’ll use this to create a new “year” column that has just the year that well was started. It will help us plot data later. We’re going to do this is two steps. We’ll first write the function to make sure it working like we want, then we’ll assign the result back to the wells data frame. Mutate and select You’ll end up with two columns. We added the select() function so we didn’t have to dig through the data frame to see if it worked. Now we can modify the code chunk to save our changes: Before the code chunk, write out what we are doing. Add a Markdown headline and description of our task: to add a “year” column. Name the chunk by adding add_year inside the {r} part of the chunk. Remove the pipe and the select() statement, as we don’t want to lose those columns for realz. Edit the first line wells %&gt;% to wells &lt;- wells %&gt;% to assign the mutate result back to our wells data frame. wells &lt;- wells %&gt;% mutate(year_drilled = year(drilling_start_date)) When you do this, it won’t print the table to the screen anymore because you’ve instead reassigned it. Inspect the wells data frame within the Environment tab and to make sure it was created properly. Like with filter(), we can create more than one column within the same mutate() function by separating them with commas. 5.9.1 Your turn to mutate Modify the above mutate function to also add a month_drilled column. 5.10 Summarize() The summarize() and summarise() functions compute tables about your data. They are the same function, as R supports both the American and European spelling of summarize. I don’t care which you use. Learn about your data with Summarize() Much like the mutate() function, we list the name of the new column first, then assign to it the function we want to accomplish using =. Let’s find the average borehole_depth of all the wells. Attempt to find the mean But, our return isn’t good? What’s up with that? 5.10.1 ignoring na In short, you can’t divide by zero or a NULL or NA value. I’ll show you how to ignore them, but first we should find out how many there are: Find NA values Take a look at this and guess what is happening. Clearly is.na is a thing. How is it being used? There are 22 records returned out of 18k+. Can we safely exclude them? I think so. We can apply a similar function na.rm function inside our summarise() filter to remove the missing values before the calculation, like this: NAs removed from summarize A mean (or average in common terms) is a way to use one number to represent a group of numbers. It works well when the variance in the numbers is not great. Median is another way, and sometimes better when there are high or low numbers that would unduly influence a mean. 5.10.2 Your turn with summarise Like filter and mutate, you can do more than one calculation within a summarize function. Edit the code chunk above in two ways: Make sure to name the code chunk, something like depth_summaries. Modify the summarise function to also create a median_depth summary. Look at your dplyr cheat sheet or google to find out how. 5.11 Group_by() The summarise() function is an especially useful in combination with another function called group_by(), which allows us to pivot tables to count and measure data by its values. Group by This is easier to understand when you can see an example, so let’s do it. 5.11.1 Group and count So, we have more than 18,000 wells, but we don’t know how many of each kind. We could filter them one-by-one, but there is an easier way. Group and count Let’s break this down: We start with the wells data frame. We then group_by the data by the proposed_use. If we print the data frame at this point, we won’t really see a difference. The group_by() function always needs another function. We then summarise the grouped data. In this case, we are creating a column called count, and we are assigning to is a special function n() which counts the number of records within each group. The result is for each unique value in the prospose_use column, we get the number of records that have that have that value. We then arrange the resulting table in descending order by our new column, count, so we can see which value has the most records. We can see that “Domestic” wells are more prevalant by a wide margin. If page through the list, you’ll see that to get an accurate count of each type of well, we’ll need to do some data cleaning. We’ll do that at another time. Let’s walk through another example: Group and summarise 5.11.2 Your turn to group How many wells were drilled in each county? Use the same group_by and summarise method to make a table that counts wells drilled in each county. Since you can summarise by more than one thing, try to find the count and average (mean) borehole_depth of wells by proposed use. You can copy the first summary we did and work from that, editing the summarise statement. 5.11.3 Counting only We’ll use summarize to do more than count, but if counting is all you want to know, there is an easier way. (I’ll try not to show you too many alternate methods … there are many ways to do everything, but this is worth knowing.) well %&gt;% count(proposed_use) It creates a column named “n” with the count. You could then use rename(new = old) to call it something else, like “wells_drilled”. 5.12 Transform review This has been a lot to learn, but it is the basics of just about any data analysis … to filter, select, arrange, group and summarise values. And to create new variables with with mutate. Next, we’ll start plotting some of this data so we can see it. 5.13 Turn in your project At this point, you’ll want so save, knit to HTML and then close your project. Zip up the folder and turn it into the assignment in Canvas. "],
["cleaning.html", "Chapter 6 Cleaning 6.1 Goals 6.2 Resources 6.3 Setup and import 6.4 Clean the proposed_use column 6.5 Export your updated data frame 6.6 Future addition", " Chapter 6 Cleaning As we were looking at the proposed_use field in the wells data, we found that the values there were pretty dirty, with misspellings and unofficial designations. If we look at the official designations for Proposed Use on page 10 of the data user manual, we see there are 14 official designations, none with any of various spellings of Piezo, which looks to be monitor wells. We need to create a clean version of the proposed_use column to use with our analysis and visualizations. Typically when I discover a situation like this, I go back to my first “import and cleaning” notebook and make changes there so the work can carry through to all subsequent notebooks, but in this case we’ll just make our changes in a new notebook and then document and export the changes for future work. 6.1 Goals Create a new notebook for cleaning data Throughout the notebook, we want to explain our thoughts and goals in Markdown. Each code block should have a human readable explanation of the goal or task. Import most recent data Create cleaned proposed_use column Export data for next notebook 6.2 Resources Strings chapter from Hadley Wickham’s book, specifically about str_replace(). RDocumentation on str_replace(). 6.3 Setup and import Create a new R Notebook with a title “Wells cleaning” and a filename of 03-wells-cleaning.Rmd. In Markdown, write down our purpose and goals in your own words. Set up the tidyverse library and import the data/wells_02.rds file that we exported at the end of our last notebook. (If you don’t recall how to do this, look at your last notebook, but update the code to reflect the new filename.) For this block and all others, make sure you have a Markdown desription of the goal or task. 6.4 Clean the proposed_use column 6.4.1 Count values in a column Let’s look again at the the values in the proposed_use column of the wells data. One way to see all the unique values and also find out how many there are is to use the count() function, which is a simple pivot table. wells %&gt;% count(proposed_use) Which gives us a list that looks something like this: proposed_use n AG WELL 3 Closed-Loop Geothermal 246 Commercial 1 De-watering 33 Domestic 8408 Environmental Soil Boring 3719 Ground Well for Electric Substation 2 Industrial 102 Injection 61 Irrigation 1493 IRRIGATION/TESTWELL 1 Monitor 3354 Monitor-VMP 2 peizometer 1 Peizometer 8 piezo 1 Piezo 12 piezometer 43 Piezometer 25 Piezometer Installation 1 PLUGGING 1 Public Supply 174 Rig Supply 14 Soil Vapor Monitor 10 Stock 259 Surface Slab Repair 1 Test Well 266 Unknown 5 Vapor Monitoring Point 1 VAPOR POINT 1 We have 30 different values here that we need to combine into at most 14 categories, which are the official ones listed on page 10 of the data user manual. After looking through it and doing some Googling, I came to a couple of conclusions: Anything named “piezo” or a variant should be a Monitor well. Anything named “vapor” should be a Monitor well. Anything that isn’t on the official list should be Other. TBH, if I was writing stories about this data, I would call the TWDB and make my sure that my educated assumptions are correct. But they seem reasonable given the documentation. 6.4.2 Change values in a column So, our goal here is to create a new column that starts with the value of proposed_use, but then we search through the values for things like “piezo” and set them to something more useful. We’ll utilize a stringr function called str_replace() using regular expressions to do this, within a mutate() function, which we know we can use to create or make changes in a column data. And, of course, we need to figure out how to do it before we save it, so let’s work through it. Start by calling the wells data frame, then using mutate to create a new column from proposed_use, and then count the rows from the new column. For now, it will be the same as it was for proposed use but we’ll fix that. wells %&gt;% mutate( use_clean = proposed_use ) %&gt;% count(use_clean) 6.4.2.1 Convert to lowercase It will be much easier for us to deal with different spellings of words if everything was lower case. “Piezo” is different than “piezo”, so let’s convert everything to lower case. wells %&gt;% mutate( use_clean = tolower(proposed_use) ) %&gt;% count(use_clean) Now our results are all lowercase. It looks something like this: use_clean n ag well 3 closed-loop geothermal 246 commercial 1 de-watering 33 6.4.2.2 Clean up the piezo-ish values We still have four different versions of “piezo” and the like, which need to be labeled as “monitor”. You might check make a mental note of how many values you have for “monitor” now so we can be know that value is growing as we fix our piezos. (I have 3354 in our example, but the number will be different when the data is pulled at a later date). We can continue to stack changes inside our mutate() function to deal with this using str_replace(). There are three arguments to the str_replace() function: what column are we working on. what pattern are we looking for, as a regular expression. what value do we want it to be. We have created a new column use_clean that we want to continue to modify, so it is both our target and our source of the mutate. The pattern we want is anything that starts with the word “piezo” and “peizo” with anything that follows. The regex expression for “anything” is .*, so piezo.* with catch “piezo”, “piezometer” and “piezo installation”. We want to set any value with those terms to “monitor”, so we set up our string replace function: str_replace(use_clean, &quot;piezo.*&quot;, &quot;monitor&quot;) and add it to our list of mutates: wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*&quot;, &quot;monitor&quot;) ) %&gt;% count(use_clean) If we look at the results of that change, we see we are left with the one misspelled “peizometer”. We can fix that by adding an “or” section to our search pattern, using the regular expression key |. wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*|peizo.*&quot;, &quot;monitor&quot;) ) %&gt;% count(use_clean) Check your results and make sure that there are no longer any versions of “piezo” in use_clean. You can keep stacking these str_replace() mutates to clean further values. 6.4.2.3 Your turn: str_replace functions Now it’s up to you to add more mutate strings to clean the rest of the column to get the 14 official “Proposed Use” designations listed below. It would make sense to organize your new mutate lines in logical ways, like perhaps to capture all the terms that would go into “other” together using the | in your search pattern, like we did with piezo and peizo example above. Here’s the official list: closed-loop geothermal de-watering domestic environmental soil boring industrial injection irrigation monitor other public supply rig supply stock test unknown 6.4.2.4 Double-check our results It might make sense to do one last check of our conversions before reassigning all of changes back to the wells data frame. Change the last count() function to the following: count(use_clean) #change this line distinct(proposed_use, use_clean) # to this line The result looks something similar to this: proposed_use use_clean Irrigation irrigation Domestic domestic Monitor monitor Public Supply public supply Environmental Soil Boring environmental soil boring Closed-Loop Geothermal closed-loop geothermal Industrial industrial Piezo monitor Stock stock Piezometer monitor Test Well test Unknown unknown piezometer monitor De-watering de-watering Ground Well for Electric Substation other VAPOR POINT monitor Piezometer Installation monitor Surface Slab Repair other Monitor-VMP monitor peizometer monitor piezo monitor Vapor Monitoring Point monitor Injection injection Peizometer monitor Commercial other IRRIGATION/TESTWELL test Soil Vapor Monitor monitor PLUGGING other AG WELL other Rig Supply rig supply This will allow you to doublecheck that all your conversions happened properly. 6.4.3 Reassign your changes back to the data frame Once you have all your column changes worked out, you need to fix it up to reassign the values to the data frame, and then add Markdown commentary above it to explain the purpose of the code chunk. Edit your code chunk to remove the distinct() or count() functions at the end. Edit the code chunk to reassign the values back to wells. wells &lt;- wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*|peizo.*&quot;, &quot;monitor&quot;), # your other str_replace items ... ) 6.5 Export your updated data frame Let’s again export our data so we can use it in a new notebook. Since we are in our third notebook of this project, let’s name the file wells_03.rds. saveRDS(wells, &quot;data-out/wells_03.rds&quot;) 6.6 Future addition While this data doesn’t support it, it would be good to have here an example of how you might take a column made up of codes, like school accountability ratings being “M”, “I”, “A”, etc. and convert them to their readable values like like “Met standard”, “Needs Improvement” and “Alternative standard”. "],
["graphics.html", "Chapter 7 Graphics 7.1 Set up our Notebook 7.2 Wells per county 7.3 Resources 7.4 Further reading", " Chapter 7 Graphics ggplot2 is the data visualization library within Hadley Wickham’s tidyverse.. It uses a concept called the Grammar of graphics, the idea that you can build every graph from the same components: a data set, a coordinate system, and geoms – the visual marks that represent data points. With a hat tip to Matt Waite, the main concepts are: aesthetics: which in this case means the data which we are going to plot geometries: which means the shape the data is going to take scales: which means any transformations we might make on the data layers: which means how we might lay multiple geometries over top of each other to reveal new information. facets: which means how we might graph many elements of the same dataset in the same space The challenge to understand here is for every graphi, we start with the data, and then describe how to layer plots or pieces on top of that data. 7.1 Set up our Notebook Create a new RNotebook. Title it “Wells visualizations” and name the file 04-charts.Rmd. Load the following libraries: tidyverse, lubridate. Import our wells_03.rds data, library(tidyverse) library(lubridate) wells &lt;- readRDS(&quot;data-out/wells_03.rds&quot;) 7.2 Wells per county For our first graphic, we will plot how many wells were drilled in each county. 7.2.1 Shape our data If we are plotting wells per county, we need to first build a data frame that counts the number of wells for each county. We can use the same count() function that we used when we cleaned our data. wells_by_county &lt;- wells %&gt;% count(county) %&gt;% rename(wells_count = n) wells_by_county Let’s break this down: The first line creates the new data frame wells_by_county, starting with our wells data frame. We apply the count() function on the “county” column. This makes our basic pivot table. On the third line, we rename the “n” column that was created by count(), so it is more descriptive, calling it wells_count. So now we have a data frame with two columns: county and wells_count. We print it on the fourth line so we can inspect it. 7.2.2 The basic ggplot template The template for a basic plot is this. (The &lt;&gt; signify we are inserting values there.) ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) ggplot() is our function. We feed into it the data we wish to plot. The + is the equivalent of %&gt;% in our tidyverse data. It means we are adding a layer, and it should always be at the end of the line, not at the begginning of the next. is the type of chart or addition we are adding. They all start with the term geom_ like geom_bar, which is what we will build. The geometric function needs “aesthetics” to describe what it should look like, the main one being the mappings of the x and y axis. 7.2.3 Plot our wells by county ggplot(data = wells_by_county) + geom_bar(mapping = aes(x = county, y = wells_count), stat = &quot;identity&quot;) On the first line we tell ggplot() that we are using the we wells_by_county data. On the next, we apply the geom_bar() function to make a bar chart. It needs two things: The mapping, which are the aesthetics. We well it to plot county on the x (horizontal) axis, and wells_count on the y (vertical) axis. Because county is not a number, we have to use the stat = &quot;identity&quot; value to describe that we are using values within county. Basic county plot We can be a little little less verbose about this because ggplot() will understand we are feeding it data and mappings. ggplot(wells_by_county) + geom_bar(aes(x=county, y=wells_count), stat = &quot;identity&quot;) 7.2.4 Add a layer of text labels For each new thing that we add to our graphic, we add it with +. In this case, we want to add number labels to show the wells_count for that county. ggplot(data = wells_by_county, aes(x = county, y = wells_count)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label=wells_count), vjust=-0.25) Basic county plot 7.3 Resources R Graphics Cookbook The ggplot2 documentation ggplot2 cheatsheets 7.4 Further reading Note This article about BBC using R, ggplot. BBC created bblot package to set BBC default styles, and BBC R cookook as collection of tips and tricks to build their styled graphics. "],
["tidy.html", "Chapter 8 Tidy data", " Chapter 8 Tidy data About shaping data with tidyr. "],
["graphics2.html", "Chapter 9 Graphics II", " Chapter 9 Graphics II More on the ggplot now that we can tidy. "],
["census.html", "Chapter 10 Census 10.1 Resources", " Chapter 10 Census A mini project using census data. 10.1 Resources Census guide Sharon Machlis guide acs package (???) if News Nerdery is author of the [censusapi package] Baltimore Sun example. “sometimes i prefer the output of one over the other censusapi vs tidycensus, which is why i alternate. i also for some reason didn’t realize i could have used the R packages to download the SAIPE (poverty stats) data; in the repo I just downloaded the file from the site”. API key signup "],
["joins.html", "Chapter 11 Joins and merges", " Chapter 11 Joins and merges About joins, merges and the like. "],
["data.html", "Chapter 12 Data packages", " Chapter 12 Data packages About various data packages and such. "],
["maps.html", "Chapter 13 Maps", " Chapter 13 Maps About making maps. "],
["references.html", "References", " References Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 13.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 13.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 13.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 13.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). # download: [&quot;pdf&quot;, &quot;epub&quot;] # bookdown::pdf_book: # includes: # in_header: preamble.tex # latex_engine: xelatex # citation_package: natbib # keep_tex: yes # bookdown::epub_book: default "]
]
