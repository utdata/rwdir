[
["index.html", "Reporting with Data in R About this class About the author Other resources", " Reporting with Data in R Christian McDonald 2019-02-26 About this class This collection of lessons is intended to support the class Reporting With Data, taught by me, Christian McDonald, at the School of Journalism, Moody College of Communication, University of Texas at Austin. I’m a strong proponent of Scripted Journalism, a method of committing data-centric journalism in a programmatic, repeatable and transparent way. There are a myriad of programming languages that further this, including Python (pandas and Jupyter) and JavaScript (Observable), but we’ll be using R, RMarkdown and RStudio. R is a super powerful, open-source programming language for data that is deep with features and an awesome community of users who build upon it. No matter the challenge before you in your data storytelling, there is probably a package available to help you solve that challenge. Probably more than one. There is always more than one way to do things in R. This course is an opinionated collection of lessons intended to teach students new to R and programming for the expressed act of committing journalism. As a beginner course, I strive to make it as simple as possible, which means I may not go into detail about alternative (and possibly better) ways to accomplish tasks. About the author I’m a career journalist who most recently served as Data and Projects Editor at the Austin American-Statesman before coming to the University of Texas at Austin full-time in Fall 2018. I’ve taught data-related course at UT since 2013. UT Github: utdata Github: critmcdonald Twitter: crit Email: christian.mcdonald@utexas.edu Other resources This text stands upon the shoulders of giants and by design does not cover all aspects of using R. Here are some other useful books, tutorials and sites dedicated to R. R Journalism Examples, a companion piece of sorts to this book with example code to accomplish specific tasks. It is a work-in-progress, and quite nascent at that. R for Data Science by Hadley Wickham and Garrett Grolemund. The Tidyverse site, which has tons of documentation and help. The RStudio Cheatsheets. R Graphics Cookbook R for Journalists site by Andrew Tran, a reporter at the Washington Post. A series of videos and tutorials on using R in a journalism setting. Practical R for Journalism by Sharon Machlis, an editor with PC World and related publications, she is a longtime proponent of using R in journalism. ## Resources This DataCamp tutorial on imports covers a ton of different data types and connections. "],
["install.html", "Chapter 1 Install Party 1.1 Installing R 1.2 Installing RStudio 1.3 Install Visual Studio Code 1.4 Class project folder", " Chapter 1 Install Party Let’s get this party started. NOTE: R and RStudio are already installed on lab computers. 1.1 Installing R Our first task is to install the R programming language onto your computer. There are a number of “mirrors” which have the software. Go to the download site. Go down to USA and choose one of the links there. They should all work the same. Click on the link for your operating system. The following steps will differ slightly based on your operating system. For Macs, you want the “latest package” For Windows, you want the “base” package. You’ll need to decide whether you want the 32- or 64-bit version. (Unless you’ve got a pretty old system, chances are you’ll want 64-bit.) Here’s hoping it will be self explanatory after that. 1.2 Installing RStudio RStudio is an “integrated development environment” – or IDE – for programming in R. Basically, it’s the program you will use when doing work for this class. Go to https://www.rstudio.com and find the “Download RStudio” button. Find the “Free” versions and find the installer for your operating system and download it. Install it. Should be like installing any other program. 1.3 Install Visual Studio Code Some csv files are really big, and RStudio has a problem viewing them. A good code editor is able to look at this files and allow you to edit them. It’s a good tool to have in your arsenal. Go to the Visual Studio Code website and download the version for your operating system. 1.4 Class project folder To keep things consistent and help with troubleshooting, I’d like you to save your work in the same location all the time. On both Mac and Windows, every user has a “Documents” folder. Open that folder. (If you don’t know where it is, ask me to help you find it.) Create a new folder called “rwd”. Use all lowercase letters. When we create new “Projects”, I want you to always save them in the Documents/rwd folder. "],
["intro.html", "Chapter 2 Introduction to R 2.1 RStudio tour 2.2 Updating preferences 2.3 Starting a new Project 2.4 Using R Notebooks 2.5 Turning in our projects", " Chapter 2 Introduction to R 2.1 RStudio tour When you launch RStudio, you’ll get a screen that looks like this: Rstudio launch screen 2.2 Updating preferences There is a preference in RStudio that I would like you to change. By default, the program wants to save a the state of your work (all the variables and such) when you close a project, but that is not good practice. We’ll change that. Go to the RStudio menu and choose Preferences Under the General tab, uncheck the first four boxes. On the option “Save Workspace to .Rdata on exit”, change that to Never. Click OK to close the box. 2.3 Starting a new Project When we work in RStudio, we will create “Projects” to hold all the files related to one another. This sets the “working directory”, which is a sort of home base for the project. Click on the second button that has a green +R sign. That brings up a box to create the project with several options. You want New Directory (unless you already have a Project directory, which you don’t for this.) For Project Type, choose New Project. Next, for the Directory name, choose a new name for your project folder. For this project, use “firstname-first-project” but use YOUR firstname. I want you to be anal about naming your folders. It’s a good programming habit. Use lowercase characters. Don’t use spaces. Use dashes. For this class, start with your first name. Rstudio project name, directory When you hit Create Project, your RStudio window will refresh and you’ll see the yourfirstname-first-project.Rproj file in your Files list. 2.4 Using R Notebooks For this class, we will almost always use R Notebooks. This format allows us to write text in between our blocks of code. The text is written in a language called R Markdown, a juiced-up version of the common documentation syntax used by programmers, Markdown. It’s not hard to learn. Here’s a Markdown guide. 2.4.1 Create your first notebook Click on the button at the top-left of RStudio that has just the green + sign. Choose the item R Notebook. This will open a new file with some boilerplate R Markdown code. At the top between the --- marks, is the metadata. This is written using YAML, and what is inside are commands for the R Notebook. Don’t sweat the YAML syntax too much right now, as we won’t be editing it often. Next, you’ll see a couple of paragraphs of text that describes how to use an R Notebooks. It is written in R Markdown, and has some inline links and bold commands, which you will learn, Then you will see an R code chunk that looks like the figure below. R code chunk Let’s take a closer look at this: The three back tick characters ( found at the top left on your keyboard) followed by the {r} indicate that this is a chunk of R code. The last three back ticks say the code chunk is over. The {r} bit can have some parameters added to it. We’ll get into that later. The line plot(cars) is R programming code. We’ll see what those commands do in a bit. The green right-arrow to the far right is a play button to run the code that is inside the chunk. The green down-arrow and bar to the left of that runs all the code in the Notebook up to that point. 2.4.2 Save the .Rmd file Do command-s or hit the floppy disk icon to save the file. It will ask you what you want to name this file. Call it 01-first-file.Rmd. When you do this, you may see another new file created in your Files directory. It’s the pretty version of the notebook which we’ll see in a minute. In the metadata portion of the file, give your notebook a better title. Replace “R Notebook” in the title: &quot;R Notebook&quot; code to be “Christian’s first notebook”, but use your name. 2.4.3 Run the notebook There is only one chunk to run in this notebook, so: Click on the green right-arrow to run the code. You should get something like this: Cars plot What you’ve done here is create a plot chart of a piece of sample data that is already inside R. (FWIW, It is the speed of cars and the distances taken to stop. Note that the data were recorded in the 1920s.) But that wasn’t a whole lot of code to see there is a relationship with speed vs stopping distance, eh? 2.4.4 Adding new code chunks The text after the chart describes how to insert a new code chunk. Let’s do that. Add a return after the paragraph of text about code chunks, but before the next bit about previews. Use the keys Cmd+Option+I to add the chunk. Your cursor will be inserted into the middle of the chunk. Type in this code in the space provided: # update 52 to your age age = 52 (age - 7) * 2 Change for “52” to your real age. With your cursor somewhere in the code block, use the key command Cmd+Shift+Return, which is the key command to RUN ALL LINES of code chunk. NOTE: To run an individual line, use Cmd+Return while on that line. Congratulations! The answer given at the bottom of that code chunk is the socially-acceptable maximum age of anyone you should date. Throwing aside whether the formula is sound, let’s break down the code. # update 52 to your age is a comment. It’s a way to explain what is happening in the code without being considered part of the code. age = 52 is assigning a number (52) to a variable name (age). A variable is a placeholder. It can hold numbers, text or even groups of numbers. They are key to programming because they allow you to change the value of the variable as you go along. The next part is simple math: (age - 7) * 2 takes the value of age and subtracts 7, then multiplies by 2. When you run it, you get [1] 90. That means there was one observation, and the value was “90”. For the record, my wife is much younger than that. Now you can play with the age variable assignment to test out different ages. 2.4.5 Practice adding code chunks Now, on your own, add a similar code chunk that calculates the minimum age of someone you should date, but using the formula (age / 2) + 7. Add a comment in the code that explains what it is for. 2.4.6 Preview the report The rest of the boilerplate text here describes how you can Preview and Knit a notebook. Let’s do that now. Press Cmd+Shift+K to open a Preview. This will open a new window and show you the “pretty” notebook that we are building. Preview is a little different than Knit, which runs all the code, then creates the new knitted HTML document. It’s Knit to HMTL that you’ll want to do before turning in your assignments. 2.4.7 The toolbar One last thing to point out before we turn this in: The toolbar that runs across the top of the R Notebook file window. The image below explains some of the more useful tools, but you REALLY should learn and use keyboard commands when they are available. R Notebook toolbar 2.4.8 Knit the final workbook Save your File with Cmd+S. Use the Knit button in the toolbar to choose Knit to HTML. 2.5 Turning in our projects If you now look in your Files pane, you’ll see you have four files in our project. (Note the only one you actually edited was the .Rmd file.) Files list The best way to turn in all of those files into Canvas is to compress them into a single .zip file that you can upload to the assignment. In your computer’s Finder, open the Documents/rwd folder. Follow the directions for your operating system linked below to create a compressed version of your yourname-final-project folder. Compress files on a Mac. Compress flies on Windows. Upload the resulting .zip file to the assignment for this week in Canvas. Here is what the compression steps looks like on a Mac: Compress file: Mac If you find you make changes to your R files after you’ve zipped your folder, you’ll need to delete the zip file and do it again. Because we are building “repeatable” code, I’ll be able to download your .zip files, uncompress them, and the re-run them to get the same results. Well done! You’ve completed the first level and earned the Beginner badge. "],
["import.html", "Chapter 3 Importing data 3.1 Goals for this section 3.2 Data types 3.3 Create a new project 3.4 Let’s get some data 3.5 Import csv as data 3.6 Assign our data to a data frame 3.7 Inspect the data 3.8 Turn in your project 3.9 Practice assignment: Import census", " Chapter 3 Importing data 3.1 Goals for this section Learn a little about data types available to R. Practice organized project setup. Learn about R packages, how to install and import them. Learn how to import CSV files. Introduce the Data Frame/Tibble. We will do this through working with well drilling reports from the Texas Water Development board. We’ll pull reports from counties in the Austin MSA and be able to see the kinds of wells dug, where they are and the pace of drilling. 3.2 Data types After installing and launching RStudio, the next trick is to import data. Depending on the data source, this can be brilliantly easy or a pain in the rear. It all depends on how well-formatted is the data. In this class, we will primarily be importing Excel files, CSVs (Comma Separated Value) and APIs (Application Programming Interface). CSVs are a kind of lowest-common-denominator for data. Most any database or program can import or export them. Excel files are good, but are often messy because humans get involved. There are often multiple header rows, columns used in multiple ways, notes added, etc. Just know you might have to clean them up before using them. APIs are systems designed to respond to programming. In the data world, we often use the APIs by writing a query to ask a system to return a selection of data. By definition, the data is well structured. You can often determine the file type of the output as part of the API call, including … JSON (or JavaScript Object Notation) is the data format preferred by JavaScript. R can read it, too. It is often the output format of APIs, and prevalent enough that you need to understand how it works. We’ll get into it more later. Don’t get me wrong … there are plenty of other data types and connections available through R, but those are the ones we’ll deal with most in the class. 3.2.1 What is clean data The Checking Your Data section of this DataCamp tutorial has a good outline of what makes good data, but in general it should: Have a single header row with well-formed column names. Once column name for each column. No merged cells. Short names are better than long ones. Spaces in names make them harder to work with. Use and _ or . between words. Remove notes or comments from the files. Each column should have the same kind of data: numbers vs words, etc. Each row should be an In our first lesson, we’ll be using a CSV file that has several rows of description at the top. We’ll be able to skip those description lines when we import. 3.3 Create a new project We did this in our first lesson, but here are the basic steps: Launch RStudio Use the +R button to create a New Project in a New Directory Name the project yourfirstname-wells and put it in your ~/Documents/rwd folder. Use the + button to use R Notebook to start a new notebook. Change the title to “Wells drilled in Austin MSA”. Delete the other boilerplate text. Save the file as 01-wells-import.Rmd. 3.3.1 The R Package environment We have to back up from the step-by-step nature of this lesson and talk a little about the R programming language. R is an open-source language, which means that other programmers can contribute to how it works. It is what makes R beautiful. What happens is developers will find it difficult to do a certain task, so they will write an R “Package” of code that helps them with that task. They share that code with the community, and suddenly the R garage has an “ultimate set of tools” that would make Spicoli’s dad proud. One set of these tools is Hadley Wickham’s Tidyverse, a set of packages for data science. These are the tools we will use most in this course. While not required reading, I highly recommend Wickham’s book R for data science, which is free. We’ll use some of Wickham’s lectures in the course. There are also a series of useful cheatsheets that can help you as you use the packages and functions from the tidyverse. We’ll refer to these throughout the course. 3.3.2 Installing and using packages There are two steps to using an R package: Install the package using install.packages(&quot;package_name&quot;). You only have to do this once for each computer, so I usually do it using the R Console instead of a script. Include the library using library(package_name). This has to be done for each Notebook or script that uses it, so it is usually one of the first things in the notebook. We’re going to install several packages we will use in the Wells project. To do this, we are going to use the Console, which we haven’t talked about much. The Console and Terminal Use the image above to orient yourself to the R Console and Terminal. In the console, type in install.packages(&quot;tidyverse&quot;) and hit return. You’ll see a bunch of commands work through your Console. Remember that you only have to install a package to your computer once. We’ll need another package, so also do: install.packages(&quot;janitor&quot;) We’ll use some commands from janitor to clean up our data column names, among other things. A good reference to learn more is the janitor vignette. I start every data project with these two packages. 3.3.3 Load the libraries Next, we’re going to tell our R Notebook to use these two libraries. After the metadata at the top of your notebook, use Cmd+option+i to insert an R code chunk. In that chunk, type in the two libraries and run the code block with Cmd+shift+Return. It will look like this: Libraries imported 3.4 Let’s get some data I could’ve supplied you with the raw data, but it is not hard to find and grab yourself, so let’s do that. Because I want you to teach you good data project skills, I want you first to make a folder to store your raw data. It’s good practice to separate your raw data from any other output or data. It will make it easy for others to find, and can help you avoid overwriting that raw data, which should remain a pristine copy. In the Files pane, use the New Folder button to create a folder called data-raw. (I typically make a data-out or similar folder for any files that I create.) In a web browser, go to the Texas Water Development Board Driller Reports page and then click on the Well Reports Search by County and Use link. In the County drop down, choose: Bastrop, Caldwell, Hays, Travis and Williamson counties. In the Proposed Use column, choose **Select All*. Click View Reports. You’ll get 400+ returns. Look for the floppy disk/arrow icon that is the download button. Choose CSV (comma delimited). That file should end up in your Downloads folder. Use your finder to move this into your project folder in the data-raw folder you created. This document has some descriptions of fields we may need later. 3.4.1 Inspect the data We want to look at the data so we understand it. In the Files pane, click on the data-raw folder to open in. Click on the WellsRpts_County_Use.csv file until you get the drop down that says View Files. View file When you choose that, you’ll get a warning that it is a big file. It should open it just fine, into a new window. It will look like this: Wells file The numbers on the left are row numbers in the file. Because lines will wrap in your window, those numbers let you know where each line starts. Note that the real header for this file starts as line 5, which means when we import this file, we need to skip the first four lines. You can close this file now. 3.5 Import csv as data Now we need to start adding some text to indicate what we are doing, which right now we are importing the file. So, write some text in Markdown that describes where the data came from and what it is. Write where the data came from. Include the link to the web page. Include which counties were included, and which After your descriptions, add a new code chunk (Cmd+option+i). Inside the chunk, add the following and hit return, then I’ll explain: read_csv(&quot;data-raw/WellRpts_County_Use.csv&quot;) read_csv() is the function we are using the load the data. This version from the readr package in the tidyverse is different from read.csv that comes with R. It is mo betta. Inside the parenthesis is the path to our data, inside quotes. If you start typing in that path and hit tab, it will complete the path. (Easier to show than explain). This prints two things to our notebook, which are shown as tabs. The first resultc called “R Console” shows what columns were imported and the data types. It’s important to review these to make sure things happened the way that you want. When I look at this, I’m struck that the column names all start with “Textbox”, which wasn’t what I expected when I was looking at the data on the website. (FWIW, the fact the text is in red is NOT an indication of a problem.) Show cols The second result prints out the data like a table. The data object is called a Tibble, which is a fancy version of a data frame that is part of the tidyverse. I will often call a tibble a “data frame”, which is the generic R from of this data structure. Think of data frames and tibbles like a well-structured table in a spreadsheet. They are organized rows of data with columns where every item in the column is of the same data type. Show imported data What went wrong? Remember that our data doesn’t really start until line five. We need to modify our import to skip the first for lines. But how does we find out how to do that? Help is on the way!! 3.5.1 Help files Another tab over by your Files pane is the Help pane. Click on the Help pane In the search box, type in read_csv and hit Return. What you get in return is information about that function. Any function loaded into RStudio also comes with these help files. The documentation style might look foreign at first, but you’ll get used to reading them. If we look through this one, we can see there is a skip = x option we can add to our import to skip lines. Modify the import line to this and then rerun the entire chunk with Cmd+shift+Return: read_csv(&quot;data-raw/WellRpts_County_Use.csv&quot;, skip = 3) I first tried skip = 4, but then it didn’t properly use the header row, I think because the readr package skips empty rows by default. 3.6 Assign our data to a data frame As of right now, we’ve only printed the data to our screen. We haven’t “saved” it at all. What we need to do next is “assign” it to a data frame. It’s kind of weird, but the convention in R is to work from right to left. We name things before we fill them with stuff. So, to create a data frame, the structure is this: new_data_frame &lt;- stuff_going_into_new_data_frame We have our stuff as the output of our read_csv() function … now we need to assign it to a data frame we will call wells. Edit your existing code chunk to look like this: wells &lt;- read_csv(&quot;data-raw/WellRpts_County_Use.csv&quot;, skip = 3) Run that chunk and two things happen: We no longer see the result printed to the screen. That’s because we created a data frame instead. In the Environment tab at the top-right of RStudio, you’ll see wells listed. Click on the blue play button next to wells and it will expand to show you a summary of the columns. Click on the name and it will open a “View” of the data in another window, so you can look at it, sort of like a spreadsheet. 3.7 Inspect the data Now that you are looking at the data, take a look at both the data types in the Environment tab, along with the View of the data. Take special care to look at the data types and examples to see if they make sense to you. Some things to consider: Are numbers actually numbers or characters? Are there numbers that should be strings, like ZIP codes? Have integers been imported as double numbers or vice versa? Are dates imported properly? 3.7.1 Write notes about things to change In text below the table output, I want you to write out a list of all the things you might have to fix in this data frame. We’ll fix them in the next lesson, as well as start looking more closely at the data. 3.8 Turn in your project Congratulations! You have created a new project in R and imported data. That is a feat of skill worth celebrating, so we will turn in this in as an assignment. Save your .Rmd file. Use the Preview/Knit button to Knit your report to HTML. Look your report over and make sure you like it. If you need to, edit your .Rmd file, save, reKnit. When you are ready, go under the File menu to Close project. Go into your computer’s finder and locate your firstnanme-wells project. Create a .zip file of the folder. Upload it to the proper assignment in Canvas. 3.9 Practice assignment: Import census To practice these skills on your own, you’ll create a new project and use new data. You’ll work on it through multiple lessons, applying what you’ve learned along the way. Create a new Project called “firstname-census-practice”. You’ll want to save that inside your “rwd” folder so you can use it later. We’ll keep building on it. Create a new folder in your project called “data-raw”. Download this CSV file and put it into your data-raw folder: DEC_10_SF1_TX_County_population.csv. The data is 2010 Census populations by county and race for Texas. Start a new R Notebook with a good title and filename. Write text to describe the data set. Import the data using read_csv() and print the data to the screen. Compare the imported data to the original csv file and note any problems you might see with the column names or data types that you might want to fix. Save, Knit, and Zip the project folder and upload to the “Practice: Import” assignment. "],
["columns.html", "Chapter 4 Columns 4.1 Goals for this section 4.2 Relaunch the Wells project 4.3 Clean up column names 4.4 Clean data within columns 4.5 Export the data 4.6 Turn in wells 4.7 Practice assignment: Clean census names", " Chapter 4 Columns I’m a bit anal about cleaning up column names in my data frames, because it makes them easier to work with later. As such, I’m going to show you three different ways to clean or edit column names. 4.1 Goals for this section Use the janitor plugin to clean columns names Mass rename columns with a pattern match Rename individual columns Fix data columns and other data types 4.2 Relaunch the Wells project Launch RStudio. It will probably open to the last project you worked on. Open your Wells project. There are several ways you can accomplish this: If you’ve had the project open before, you can use the drop down in the top-right of RStudio to see a list of recent projects, and choose it from there. Or, under the File menu to Recent projects and choose it. Or, under File you can use Open Project… and go to that folder and choose it. Look in the Files pane to the right and fine your 01-wells-import.Rmd file and open it. Use the Run button in the R Notebook toolbar to Run All of the chunks, which will load all your data and load the data frame from our last assignment. However you do it, make real sure you are in your wells project and that you are in your 01-wells-import.Rmd file. 4.3 Clean up column names At the end of our last lesson, we printed the wells data frame to the screen and clicked through the columns to look at the data. I like my column names to be standardized: Spaces in names make them harder to work with. Use and _ or . between words. Short names are better than long ones. lower_case is nice. 4.3.1 Clean names with janitor I use function from the “janitor” package called clean_names that will standardize column names. Often, this is all I need to do. After your list of things to fix, write a Markdown headline ## Clean column names. Using the ## makes this a smaller headline than the title. (The more #’s the smaller the headline.) The idea is to use these to organize your code and thoughts. Explain in text that we’ll use janitor to clean the column names. Insert a new code chunk (Cmd+shift+i should be second nature by now.) Insert the name of your wells data frame and run it to inspect the column names again. These are not too bad, but they are a mix of upper and lowercase names, and some of them are rather long. We’ll try the janitor clean_names function first. In a new code chunk, start with the wells data frame. wells %&gt;% clean_names() And you’ll get a result like this: Columns cleaned with janitor 4.3.1.1 About the pipe Let’s take take a moment to talk about this %&gt;% text you see there. (It’s called a pipe for dumb reasons I don’t want to get into). Think of it as the “And THEN do THIS” key. It takes the result of what is on the left, and allows you to then THEN do the thing on the right. We will use the %&gt;% pipe command a lot, so it is worth knowing that the keyboard command Cmd+shift+m will give you that string of characters. I did NOT invent this keyboard command, but you might remember that Professor McDonald taught it to you. It will serve you well. Remember: Think of the %&gt;% command as “Then”. So, we first have the wells data frame, THEN we are cleaning the names. 4.3.1.2 Assign clean names back to wells Now, we haven’t actually changed the names for realz, we just printed the data frame to our screen with those new names. We have to assign those changes somewhere to keep them. We could create a new data frame, but in this case, we’ll just replace our current wells with our new wells, similar to how we filled wells the first time with our raw data. Like this: wells &lt;- wells %&gt;% clean_names() The result no longer prints to our screen, but we can look at our Environment tab and check on our results, if we want. This is a start, but we still have some problems: We have some long names, like “well_report_tracking_number2”. We have an annoying trailing “2” at the end of all the column names. 4.3.2 Simple renaming of individual columns Renaming individual columns is pretty simple, and is another example of the “piping” concept of data %&gt;% do_something(). In this case, we’ll be useing the rename() function, which works like this: rename(new_column_name = old_column_name)` The = assignment works from-right-to-left, just of like &lt;- does when we put data into a data frame. So, let’s apply this to our wells data frame: Add Markdown text that says we are going to rename two columns: well_report_tracking_number2 and plugging_report_tracking_number2. Add a new code chunk and print the wells data frame. Now go back and add a %&gt;%pipe and the rename function, like the following: wells %&gt;% rename(well_number = well_report_tracking_number2) Do Cmd+Return to run that line, and you’ll see the first column name has changed. Note that is still ONE line of code, even though it is written in multiple lines. We can rename more than one column at at time if we separate the assignments with commas. Now, let’s edit this to also change the plugging_report_tracking_number2 column, which is the last column of the data. In the same code chunk, add a comma and a return before the ending ). add the new column mapping, like this: wells %&gt;% rename(well_number = well_report_tracking_number, plug_number = plugging_report_tracking_number) Note the indents in the code there. RStudio probably indented it properly for you, but it’s done that way so you can visually see that these two lines are are related. We could do all the column names that way to remove the “2”, but I want to show you a different way below to change them all at once. 4.3.2.1 Assign renamed columns back to wells Now, again, we have printed these column name chages to our screen, but we have not yet saved them back to the wells data frame. We need to assign it back to wells. Add wells &lt;- to the beginning of the code chunk so what had printed to the screen is now instead being pushed into the wells data frame. wells &lt;- wells %&gt;% rename(well_number = well_report_tracking_number2, plug_number = plugging_report_tracking_number2) NOTE: An important concept: Now that you have permanently changed the wells data frame, you can’t run that same code chunk again or it will give you an error. Why? because “well_report_tracking_number2” doesn’t exist anymore, so R can’t find it to change it! If you need to re-run that chunk, you need to first re-run all the code above it, either by using the down-arrow play button on the chunk or going up to the Run menu and chosing “Run All Chunks Above”. 4.3.3 Mass renaming of columns While we could individually rename all the columns to remove the trailing “2” on all the names, there is a way to do it all at once. It’s the last way we’ll discuss how to change column names, as I’ve already broken my rule of showing you only one way to do something. This is worth it because it saves time and introduces a couple of useful concepts. We can access all the column names of a data frame with a generic R function called names(), and we can use a pattern matching replacement called str_replace() to change them. Write in text that we are going to change the names of all the columns to remove the “2”. Create a new code block and insert this: names(wells) Run that, and you get a return like this, which is a list of all the column names of your data frame. [1] &quot;well_number&quot; &quot;type_of_work2&quot; &quot;proposed_use2&quot; &quot;owner_name2&quot; [5] &quot;county2&quot; &quot;well_address2&quot; &quot;coord_dd_lat2&quot; &quot;coord_dd_long2&quot; [9] &quot;grid_number2&quot; &quot;drilling_start_date2&quot; &quot;drilling_end_date2&quot; &quot;borehole_depth2&quot; [13] &quot;driller_signed2&quot; &quot;driller_company&quot; &quot;license_number2&quot; &quot;plug_number&quot; Cool, we can now use the %&gt;% pipe to “THEN” perform actions on those names, just like we did on the data frame above. The next function we’ll use to do that is str_replace() which allows us to search and replace strings. It works like this: `str_replace(data, &quot;search_pattern&quot;, &quot;replacement_text&quot;)` In our case, the “data” will be passed into it with the pipe. We want to replace “2” with nothing, so we’ll do this: names(wells) %&gt;% str_replace(&quot;2&quot;, &quot;&quot;) Let’s break that down again: We start with names(wells) which gives us a list of our column “names”. We use the %&gt;% to THEN apply a new function called str_replace(), which allows use to replace strings of text. Our data has been passed in by the pipe, so our our next argument is to search for the character &quot;2&quot; in all the names. And we replace those 2s with and empty string &quot;&quot;, which essentially deletes them. 4.3.3.1 Assign the replaced column names back into names(wells) Like our other examples, we have to now save our changes, but this one is a little different. Since we are only working with the names of the data with names(wells), we need to assign the back the same way, into names(wells). Add names(wells) &lt;- to the first line of the code chunk so we assign the names back. names(wells) &lt;- names(wells) %&gt;% str_replace(&quot;2&quot;,&quot;&quot;) 4.4 Clean data within columns Now that we’ve cleaned up our column names, our next task is to clean up some of the data itself. 4.4.1 Using lubridate to clean dates Fixing dates in generic R can be a semi-complicated process. Luckily, the tidyverse package lubridate makes date conversions simple. The package was included when we installed the tidyverse package, but we need to add the library. Go back to the top of your R Notebook where the libraries are loaded, and add this line and run it: library(lubridate). Return back to the bottom of the Notebook and add in Markdown a headline and text describing that you will use lubridate to convert the date fields. Insert a new code chunk and add and run this, then I’ll explain it: wells %&gt;% mutate(drilling_start_date = mdy(drilling_start_date)) Go head and click over to the drilling_start_date column so you can see the converted date. We started with the wells. We then piped the results into mutate(), which “mutates” data within columns. Mutate is not just for dates and we will use it to change and create all kinds of changes in the future. The first argument of mutate is the name of the new column. In this case, we are changing the existing column, so we are using drilling_start_date. = is the assignment operators. What is on the right will be put into the left. mdy(drilling_start_date) is the lubridate function. We are telling lubridate that the format of the existing text field is in Month/Day/Year format. Lubridate is smart enough to realize the / separates the dates, and it would also understand if the separators were - or .. That’s kind of weird. We are telling lubridate that we are starting with mdy so it will convert and show it back to us in yyyy-mm-dd, which is standard database data format. 4.4.1.1 Your turn It’s time for you to use some of the skills you’ve learned already to accomplish a couple of easy tasks: Update the mutate() function above to also update drilling_end_date field to a date. Hint: mutate is a tidyverse function just like rename, so it works similarly. Assign the changes you’ve made back to the wells data frame and then reprint it to make sure it’s all good. 4.4.2 Fix the bore hole depth If you look at the CSV data, the borehole_depth is and integer (a number without a decimal point), but it was imported as a &lt;dbl&gt; number with decimals. This could cause us problems later if we wanted to math on these, so we’ll convert this to an integer using mutate(). Add a Markdown headline and description to describe our actions. Add a code chunk and add the following and run it: wells %&gt;% mutate(borehole_depth = as.integer(borehole_depth)) wells This will reassign that column as an integer. How did I know to use as.integer? I Googled “r convert float to integer” and found this tutorial and this Stack Overflow article. A side note about this: I didn’t realize this might be a problem until a later lesson. If I found a problem like this in Excel, I would have to redo all my steps, but since I’m using a script, I was able to make this change and then rerun the notebook. As a last step, we have to reassign our mutated data frame back to wells, so change the first line to wells &lt;- wells %&gt;%. 4.5 Export the data It’s not a bad idea to organize a project into multiple R Notebooks. I’ll often create my first notebook to complete the tasks of downloading and cleaning up data, and then create a new one to handle analysis, etc. (This is why I had you name the files 01-wells.Rmd.) It’s possible to output the data frame you have created with all the changes and datatypes into a special .rds format that will re-import into R in exactly the same form. We’ll do that now. Create a new Markdown header and text description to explain that you are exporting the data. Use the Files pane to create a New Folder called data-out. (If the folder doesn’t exist already, you’ll get an error trying save the file.) Create a new code chunk and add the following and run it: wells %&gt;% saveRDS(&quot;data-out/wells_01.rds&quot;) To break that down: We are staring with wells We are piping that into the saveRDS() function. We are giving saveRDS() the path to save the file. DO NOT update this to assign back into the wells data frame. We don’t have to do that here since our output is an external file. DO use your Files pane to make sure it worked and you actually saved out the file. 4.6 Turn in wells Congratulations! You finished this chapter, having renamed columns and changed data types. Depending on where we are in the week, you may be asked to turn this in at this stage. In any event, you should save and Knit your files. 4.7 Practice assignment: Clean census names You will start with the “census-practice”&quot; project that you started in the previous chapter, so the first step is to open that project in RStudio. The goal here is to rename the columns in the data to shorter, more-friendly names, such as “black” instead of “Not Hispanic - Black alone”, or “american_indian” instead of “Not Hispanic - American Indian alone”. Use clean_names() to standardize them. Use either rename() or str_replace() on names() to rename the columns. It doesn’t matter to me how what method you use to change them, as long as it gets done. Make sure each step is documented in Markdown with good headlines and descriptions. Save the resulting data out as an “.rds” file into a data-out folder. Save, Knit, Zip and submit your project folder to the “Practice: Columns” assignment. "],
["transform.html", "Chapter 5 Transform 5.1 Goals for the section 5.2 Introducing dplyr 5.3 Start a new R Notebook 5.4 Record our goals 5.5 Name your code chunks 5.6 Import our data 5.7 Filter() 5.8 Combining filters 5.9 Arrange() 5.10 Multi-step operations 5.11 Select() 5.12 Mutate() 5.13 Summarize() 5.14 Group_by() 5.15 Transform review 5.16 Turn in your in-class project 5.17 Practice assignment: Transforms on census", " Chapter 5 Transform 5.1 Goals for the section Pay more attention to the Markdown to record our goals, actions and explain our code. We’ll name our code chunks, too. Use the dplyr tools to filter, sort and create new columns of data. 5.2 Introducing dplyr One of the packages within the tidyverse is dplyr ( cheatsheet ) which allows us to transform our data frames in ways that let us explore the data and prepare it for visualizing. It’s the R equivalent of common Excel functions like sort, filter and pivoting. dplyr functions (Some slides included here are used with permission from Hadley and Charlotte Wickham.) 5.3 Start a new R Notebook As I explained at the end of our last lesson, it’s a good practice to separate your import/cleaning functions from your analysis functions into separate notebooks, so we’ll create a new one for our analysis. Launch RStudio and open your wells project. Create a new R Notebook and set a new title of “Wells exploration and analysis”. Remove the boilerplate language and add a description of our goals: To explore an analyze our wells project. Mention that you have to run the other notebook first in case your someone else (or your future self) comes here first. Save your file as 02-wells-explore.Rmd. 5.4 Record our goals What do we want to learn about these wells? Look over the columns and some of the values in them and come up with a list of at least five things you might want to learn from the data. Add a Markdown headline ## Goals. Create a bullet list of things you might want to find. Use a * or - to start each new line. We’ll review some of your ideas in class. 5.5 Name your code chunks By adding the word setup after our the {r} at the beginning, then we can find that chunk in our navigation drop down at the bottom of the R Notebook window. R Notebook navigation 5.6 Import our data Add a Markdown headline and description that you are loading the data. Add a code chunk named import with the following: Wells data imported Now we are back to where we ended with the first notebook. 5.7 Filter() We can use dplyr’s filter() function to capture a subset of the data, like all the wells in Travis County. It works like this: dplyr filter function Let’s filter our wells data to just those in Travis County. We are going to use the %&gt;% pipe function to do this to the wells data frame. Travis wells When you run this, you’ll see that you the about 9000 rows instead of the 18,000+ of the full data set. Note the two equals signs there ==. It’s important two use two of them, as a single = will not work, as that means something else. There are a number of these logical test operations: dplyr logical tests 5.7.1 Filter your turn Create new code blocks and filter for each of the following: Wells with a proposed use of Irrigation. Wells at least 1000 feet deep. One more that might help you answer one of your goals you listed above. 5.7.2 Common mistakes with filter Some common mistakes that happen when using filter. 5.7.2.1 Use two == signs for “true” DON’T DO THIS: wells %&gt;% filter(county = &quot;Travis&quot;) DO THIS: wells %&gt;% filter(county == &quot;Travis&quot;) 5.7.2.2 Forgetting quotes DON’T DO THIS: wells %&gt;% filter(county == Bastrop) DO THIS: wells %&gt;% filter(county == &quot;Bastrop&quot;) 5.8 Combining filters You can filter for more than one thing at a time by separating more than one test with a comma. wells %&gt;% filter(county == &quot;Travis&quot;, proposed_use == &quot;Irrigation&quot;) If you use a comma to separate tests, then both tests have to be true. If you want OR, then you use a pipe | (the shift-key above the backslash.) Boolean operators 5.8.1 Your turn combining filters Your quest is to filter to wells in Travis or Williamson counties that have a start date in 2018. BIG HINT: If you include library(lubridate) in your notebook then you can access the year of a field with year(name_of_date_field). 5.8.2 Common mistakes with combining filters Some things to watch when trying to combine filters. 5.8.2.1 Collapsing multiple tests into one DON’T DO THIS: wells %&gt;% filter(county == &quot;Travis&quot; | &quot;Williamson&quot;) DO THIS: well %&gt;% filter(county == &quot;Travis&quot; | county == &quot;Williamson&quot;) BUT EVEN BETTER: wells %&gt;% filter(county %in% c(&quot;Travis&quot;, &quot;Williamson&quot;)) If you want to combine a series of strings in your filter, you have to put them inside a “concatenate” function, which is shortened to c(), as in the example above. 5.9 Arrange() The arrange() function sorts data. dataframe %&gt;% arrange(column) Or, to arrange in descending order (biggest on top): dataframe %&gt;% arrange(desc(column)) So, let’s sort our data by the borehole depth: wells %&gt;% arrange(borehole_depth) You’ll have to scroll the columns over to see it, and the depths start at zero, which is not very sexy. As journalists, we usually want to see the largest (or deepest) thing, so we can arrange the column in descending order with this: Deepest wells Now we see some deep wells … 3300 feet when I pulled my test data. 5.10 Multi-step operations But what if you want to both filter and arrange? It is possible to chain piped opperations together. Let’s find the deepest well in Travis County: wells %&gt;% filter(county == &quot;Travis&quot;) %&gt;% arrange(desc(borehole_depth)) 5.10.1 Your turn to combine and pipe Find a list of the deepest irrigation wells in Travis County in 2017. Use the pipe to string together your functions. 5.11 Select() As we’ve worked with borehole_depth it’s been kind of a pain to tab through all the fields to see the result we want. The select() function allows you to choose which fields to display from a data frame. If we are only interested in the owner and borehole_depth from our previous query of deepest wells in Travis, then we we can pipe the results to a select function. It works by listing the column names inside the function. You can use - before a column name to remove it. One the end of your previous code chunk, add a pipe, then select(owner_name, borehole_depth): wells %&gt;% filter(county == &quot;Travis&quot;) %&gt;% arrange(desc(borehole_depth)) %&gt;% select(owner_name, borehole_depth) The order of all these operations matter. If you use select() that removes a column, you cannot later use filter on that removed column. 5.12 Mutate() We used the mutate() function with our data cleaning, but let’s dive more into it. mutate() allows us to change data based on a formula. We can assign the change back to an existing column or create a new one. Create columns with mutate() In the example above: gapminder is the source data frame. gdp is the new column being created. it comes first. = gdpPercap * pop is the function. It is multiplying the the two columns that are in the gapminder data frame. The applied function doesn’t have to be math. It could be pulling part of a string or any number of things. We’ll use this to create a new “year” column that has just the year that well was started. It will help us plot data later. We’re going to do this is two steps. We’ll first write the function to make sure it working like we want, then we’ll assign the result back to the wells data frame. Mutate and select You’ll end up with two columns. We added the select() function so we didn’t have to dig through the data frame to see if it worked. Now we can modify the code chunk to save our changes: Before the code chunk, write out what we are doing. Add a Markdown headline and description of our task: to add a “year” column. Name the chunk by adding add_year inside the {r} part of the chunk. Remove the pipe and the select() statement, as we don’t want to lose those columns for realz. Edit the first line wells %&gt;% to wells &lt;- wells %&gt;% to assign the mutate result back to our wells data frame. wells &lt;- wells %&gt;% mutate(year_drilled = year(drilling_start_date)) As we know, when we do this the data frame will no longer print to the screen anymore because you’ve instead reassigned it. That’s OK. Inspect the wells data frame within the Environment tab and to make sure it was created properly. (If you really want to check the data on your screen, you could use head(wells) to see just the several lines.) As you may recall from our lesson on column renaming, we can create more than one column within the same mutate() function by separating them with commas. 5.12.1 Your turn to mutate Modify the above mutate function to also add a month_drilled column. 5.13 Summarize() The summarize() and summarise() functions compute tables about your data. They are the same function, as R supports both the American and European spelling of summarize. I don’t care which you use. Learn about your data with Summarize() Much like the mutate() function, we list the name of the new column first, then assign to it the function we want to accomplish using =. Let’s find the average borehole_depth of all the wells. Attempt to find the mean But, our return isn’t good? What’s up with that? 5.13.1 ignoring na In short, you can’t divide by zero or a NULL or NA value. I’ll show you how to ignore them, but first we should find out how many there are: Find NA values Take a look at this and guess what is happening. Clearly is.na is a thing. How is it being used? There are 22 records returned out of 18k+. Can we safely exclude them without affecting the results? I think so. We can apply a similar function na.rm function inside our summarise() function to remove the missing values before the calculation, like this: NAs removed from summarize A mean (or average in common terms) is a way to use one number to represent a group of numbers. It works well when the variance in the numbers is not great. Median is another way, and sometimes better when there are high or low numbers that would unduly influence a mean. 5.13.2 Your turn with summarise Like filter and mutate, you can do more than one calculation within a summarize function. Edit the code chunk above in two ways: Make sure to name the code chunk, something like depth_summaries. Modify the summarize function to also create a median_depth summary. Look at your dplyr cheat sheet or google to find out how. 5.14 Group_by() The summarise() function is an especially useful in combination with another function called group_by(), which allows us to pivot tables to count and measure data by its values. Group by This is easier to understand when you can see an example, so let’s do it. 5.14.1 Group and count So, we have more than 18,000 wells, but we don’t know how many of each kind. We could filter them one-by-one, but there is an easier way. Group and count Let’s break this down: We start with the wells data frame. We then group_by the data by the proposed_use. If we print the data frame at this point, we won’t really see a difference. The group_by() function always needs another function to see a result. We then summarise the grouped data. In this case, we are creating a column called count, and we are assigning to is a special function n() which counts the number of records within each group. The result is for each unique value in the prospose_use column, we get the number of records that have that have that value. We then arrange the resulting table in descending order by our new column, count, so we can see which value has the most records. We can see that “Domestic” wells are more prevalent by a wide margin. If page through the list, you’ll see that to get an accurate count of each type of well, we’ll need to do some data cleaning. We’ll do that at another time. Let’s walk through another example: Group and summarise 5.14.2 Your turn to group How many wells were drilled in each county? Use the same group_by and summarise method to make a table that counts wells drilled in each county. Since you can summarise by more than one thing, try to find the count and average (mean) borehole_depth of wells by proposed use. You can copy the first summary we did and work from that, editing the summarise statement. 5.14.3 Counting only We’ll use summarize to do more than count, but if counting is all you want to know, there is an easier way. (I’ll try not to show you too many alternate methods … there are many ways to do everything, but this is worth knowing.) well %&gt;% count(proposed_use) It creates a column named “n” with the count. You could then use rename(new = old) to call it something else, like “wells_drilled”. 5.15 Transform review This has been a lot to learn, but it is the basics of just about any data analysis … to filter, select, arrange, group and summarise values. And to create new variables with with mutate. Next, we’ll start plotting some of this data so we can see it. 5.16 Turn in your in-class project At this point, you’ll want so save, knit to HTML and then close your project. Zip up the folder and turn it into the assignment in Canvas. 5.17 Practice assignment: Transforms on census For this practice assignment, you’ll continue with your “census-practice” project. The goal here is: For each race in the data, find the county with the highest percentage for that race. You’ll use the dplyr commands from this lesson to do it. Start a new notebook that imports the cleaned data from the last assignment. Start the notebook name with “02-” so you know the order to run them in the future. Use mutate() to create a new column for each race that calculates the percentage for that race. You might create columns names like “hispanic_prc” with the formula “(hispanic / total_populaton) * 100”. Assign those values back to the “census” data frame. Create a series of code chunks, one for each race that does this: Arrange the data so the county with the highest percentage of that race is on top, then use select() to show these columns: The total_population, the race total, and the percentage of that race. Make sure that each each action is clearly described in Markdown headlines and text, and that each code chunk is named. If you feel like you are repeating yourself a lot on this assignment and feel like there should be a better way, I assure you there is. We will get to that. Save, Knit, Zip and upload your project to the “Practice: Transform with dplyr” assignment. "],
["cleaning.html", "Chapter 6 Cleaning 6.1 Goals for this section 6.2 Taking stock of the data 6.3 Setup and import 6.4 Clean the proposed_use column 6.5 Export your updated data frame 6.6 Future addition", " Chapter 6 Cleaning 6.1 Goals for this section Create a new notebook for cleaning data Throughout the notebook, we want to explain our thoughts and goals in Markdown. Each code block should have a human readable explanation of the goal or task. Import most recent data Create cleaned proposed_use column Export data for next notebook 6.1.1 Resources Strings chapter from Hadley Wickham’s book, specifically about str_replace(). RDocumentation on str_replace(). stringr cheatsheet. 6.2 Taking stock of the data As we were looking at the proposed_use field in the wells data, we found that the values there were pretty dirty, with misspellings and unofficial designations. If we look at the official designations for Proposed Use on page 10 of the data user manual, we see there are 14 official designations, none with any of various spellings of Piezo, which looks to be monitor wells. We need to create a clean version of the proposed_use column to use with our analysis and visualizations. Typically when I discover a situation like this, I go back to my first “import and cleaning” notebook and make changes there so the work can carry through to all subsequent notebooks, but in this case we’ll just make our changes in a new notebook and then document and export the changes for future work. 6.3 Setup and import Create a new R Notebook with a title “Wells cleaning” and a filename of 03-wells-cleaning.Rmd. In Markdown, write down our purpose and goals in your own words. Set up the tidyverse library and import the data/wells_02.rds file that we exported at the end of our last notebook. (If you don’t recall how to do this, look at your last notebook, but update the code to reflect the new filename.) For this block and all others, make sure you have a Markdown description of the goal or task. 6.4 Clean the proposed_use column 6.4.1 Count values in a column Let’s look again at the the values in the proposed_use column of the wells data. One way to see all the unique values and also find out how many there are is to use the count() function, which is a simple pivot table. wells %&gt;% count(proposed_use) Which gives us a list that looks something like this: proposed_use n AG WELL 3 Closed-Loop Geothermal 246 Commercial 1 De-watering 33 Domestic 8408 Environmental Soil Boring 3719 Ground Well for Electric Substation 2 Industrial 102 Injection 61 Irrigation 1493 IRRIGATION/TESTWELL 1 Monitor 3354 Monitor-VMP 2 peizometer 1 Peizometer 8 piezo 1 Piezo 12 piezometer 43 Piezometer 25 Piezometer Installation 1 PLUGGING 1 Public Supply 174 Rig Supply 14 Soil Vapor Monitor 10 Stock 259 Surface Slab Repair 1 Test Well 266 Unknown 5 Vapor Monitoring Point 1 VAPOR POINT 1 We have 30 different values here that we need to combine into at most 14 categories, which are the official ones listed on page 10 of the data user manual. After looking through it and doing some Googling, I came to a couple of conclusions: Anything named “piezo” or a variant should be a Monitor well. Anything named “vapor” should be a Monitor well. Anything that isn’t on the official list should be Other. TBH, if I was writing stories about this data, I would call the TWDB and make my sure that my educated assumptions are correct. But they seem reasonable given the documentation. 6.4.2 Change values in a column So, our goal here is to create a new column that starts with the value of proposed_use, but then we search through the values for things like “piezo” and set them to something more useful. We’ll utilize a stringr function called str_replace() using regular expressions to do this, within a mutate() function, which we know we can use to create or make changes in a column data. And, of course, we need to figure out how to do it before we save it, so let’s work through it. Start by calling the wells data frame, then using mutate to create a new column from proposed_use, and then count the rows from the new column. For now, it will be the same as it was for proposed use but we’ll fix that. wells %&gt;% mutate( use_clean = proposed_use ) %&gt;% count(use_clean) 6.4.2.1 Convert to lowercase It will be much easier for us to deal with different spellings of words if everything was lower case. “Piezo” is different than “piezo”, so let’s convert everything to lower case. wells %&gt;% mutate( use_clean = tolower(proposed_use) ) %&gt;% count(use_clean) Now our results are all lowercase. It looks something like this: use_clean n ag well 3 closed-loop geothermal 246 commercial 1 de-watering 33 6.4.2.2 Clean up the piezo-ish values We still have four different versions of “piezo” and the like, which need to be labeled as “monitor”. You might check make a mental note of how many values you have for “monitor” now so we can be know that value is growing as we fix our piezos. (I have 3354 in our example, but the number will be different when the data is pulled at a later date). We can continue to stack changes inside our mutate() function to deal with this using str_replace(). There are three arguments to the str_replace() function: what column are we working on. what pattern are we looking for, as a regular expression. what value do we want it to be. We have created a new column use_clean that we want to continue to modify, so it is both our target and our source of the mutate. The pattern we want is anything that starts with the word “piezo” and “peizo” with anything that follows. The regex expression for “anything” is .*, so piezo.* with catch “piezo”, “piezometer” and “piezo installation”. We want to set any value with those terms to “monitor”, so we set up our string replace function: str_replace(use_clean, &quot;piezo.*&quot;, &quot;monitor&quot;) and add it to our list of mutates: wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*&quot;, &quot;monitor&quot;) ) %&gt;% count(use_clean) If we look at the results of that change, we see we are left with the one misspelled “peizometer”. We can fix that by adding an “or” section to our search pattern, using the regular expression key |. wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*|peizo.*&quot;, &quot;monitor&quot;) ) %&gt;% count(use_clean) Check your results and make sure that there are no longer any versions of “piezo” in use_clean. You can keep stacking these str_replace() mutates to clean further values. 6.4.2.3 Your turn: str_replace functions Now it’s up to you to add more mutate strings to clean the rest of the column to get the 14 official “Proposed Use” designations listed below. It would make sense to organize your new mutate lines in logical ways, like perhaps to capture all the terms that would go into “other” together using the | in your search pattern, like we did with piezo and peizo example above. Here’s the official list: closed-loop geothermal de-watering domestic environmental soil boring industrial injection irrigation monitor other public supply rig supply stock test unknown 6.4.2.4 Double-check our results It might make sense to do one last check of our conversions before reassigning all of changes back to the wells data frame. Change the last count() function to the following: count(use_clean) #change this line distinct(proposed_use, use_clean) # to this line The result looks something similar to this: proposed_use use_clean Irrigation irrigation Domestic domestic Monitor monitor Public Supply public supply Environmental Soil Boring environmental soil boring Closed-Loop Geothermal closed-loop geothermal Industrial industrial Piezo monitor Stock stock Piezometer monitor Test Well test Unknown unknown piezometer monitor De-watering de-watering Ground Well for Electric Substation other VAPOR POINT monitor Piezometer Installation monitor Surface Slab Repair other Monitor-VMP monitor peizometer monitor piezo monitor Vapor Monitoring Point monitor Injection injection Peizometer monitor Commercial other IRRIGATION/TESTWELL test Soil Vapor Monitor monitor PLUGGING other AG WELL other Rig Supply rig supply This will allow you to double check that all your conversions happened properly. 6.4.3 Reassign your changes back to the data frame Once you have all your column changes worked out, you need to fix it up to reassign the values to the data frame, and then add Markdown commentary above it to explain the purpose of the code chunk. Edit your code chunk to remove the distinct() or count() functions at the end. Edit the code chunk to reassign the values back to wells. wells &lt;- wells %&gt;% mutate( use_clean = tolower(proposed_use), use_clean = str_replace(use_clean, &quot;piezo.*|peizo.*&quot;, &quot;monitor&quot;), # your other str_replace items ... ) 6.5 Export your updated data frame Let’s again export our data so we can use it in a new notebook. Since we are in our third notebook of this project, let’s name the file wells_03.rds. saveRDS(wells, &quot;data-out/wells_03.rds&quot;) 6.6 Future addition While this data doesn’t support it, it would be good to have here an example of how you might take a column made up of codes, like school accountability ratings being “M”, “I”, “A”, etc. and convert them to their readable values like like “Met standard”, “Needs Improvement” and “Alternative standard”. "],
["graphics.html", "Chapter 7 Graphics 7.1 Goals for this section 7.2 Introduction ggplot 7.3 Set up our Notebook 7.4 Wells per county 7.5 Wells per county over time 7.6 Your turn: Build a line chart 7.7 Review of ggplot", " Chapter 7 Graphics 7.1 Goals for this section An introduction to the Grammer of Graphics We’ll make charts! 7.1.1 Resources and further reading R Graphics Cookbook The ggplot2 documentation ggplot2 cheatsheets Note This article about BBC using R, ggplot. BBC created the bblot package to set BBC default styles, and BBC R cookook as a collection of tips and tricks to build their styled graphics. 7.2 Introduction ggplot ggplot2 is the data visualization library within Hadley Wickham’s tidyverse.. It uses a concept called the Grammar of graphics, the idea that you can build every graph from the same components: a data set, a coordinate system, and geoms – the visual marks that represent data points. With a hat tip to Matt Waite, the main concepts are: aesthetics: which in this case means the data which we are going to plot geometries: which means the shape the data is going to take scales: which means any transformations we might make on the data layers: which means how we might lay multiple geometries over top of each other to reveal new information. facets: which means how we might graph many elements of the same dataset in the same space The challenge to understand here is for every graphic, we start with the data, and then describe how to layer plots or pieces on top of that data. 7.3 Set up our Notebook Create a new RNotebook. Title it “Wells visualizations” and name the file 04-charts.Rmd. Load the following libraries: tidyverse, lubridate. Import our wells_03.rds data, library(tidyverse) library(lubridate) wells &lt;- readRDS(&quot;data-out/wells_03.rds&quot;) 7.4 Wells per county For our first graphic, we will plot how many wells were drilled in each county. 7.4.1 Shape our data If we are plotting wells per county, we need to first build a data frame that counts the number of wells for each county. We can use the same count() function that we used when we cleaned our data. wells_by_county &lt;- wells %&gt;% count(county) %&gt;% rename(wells_count = n) wells_by_county Let’s break this down: The first line creates the new data frame wells_by_county, starting with our wells data frame. We apply the count() function on the “county” column. This makes our basic pivot table. On the third line, we rename the “n” column that was created by count(), so it is more descriptive, calling it wells_count. So now we have a data frame with two columns: county and wells_count. We print it on the fourth line so we can inspect it. 7.4.2 The basic ggplot template The template for a basic plot is this. (The &lt;&gt; signify we are inserting values there.) ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) ggplot() is our function. We feed into it the data we wish to plot. The + is the equivalent of %&gt;% in our tidyverse data. It means we are adding a layer, and it should always be at the end of the line, not at the beginning of the next. is the type of chart or addition we are adding. They all start with the term geom_ like geom_bar, which is what we will build. The geometric function requires “aesthetics” to describe what it should look like, the main one being the mapping of the x and y axis. There are two ways to simplify this: It is implied that the first thing fed to ggplot is the data, so you don’t have to write out data = unless there is ambiguity. The aes() values are also implied as mappings, so you don’t have to write out mapping = unless there is ambiguity. And lastly, if the mappings are the same for all the geoms, you can put them in the ggplot line. ggplot(&lt;DATA&gt;, aes(&lt;MAPPINGS&gt;)) + &lt;GEOM&gt;(&lt;ADDITONAL_MAPPINGS&gt;) 7.4.3 Plot our wells by county Here is the verbose plot for our counties. ggplot(data = wells_by_county) + geom_bar(mapping = aes(x = county, y = wells_count), stat = &quot;identity&quot;) On the first line we tell ggplot() that we are using the we wells_by_county data. On the next, we apply the geom_bar() function to make a bar chart. It needs two things: The mapping, which are the aesthetics. We well it to plot county on the x (horizontal) axis, and wells_count on the y (vertical) axis. Because county is not a number, we have to use the stat = &quot;identity&quot; value to describe that we are using values within county. This is a special thing for bar charts. Basic county plot Our less verbose way to do this looks like this: ggplot(wells_by_county, aes(x=county, y=wells_count)) + geom_bar(stat = &quot;identity&quot;) 7.4.4 Add a layer of text labels For each new thing that we add to our graphic, we add it with +. In this case, we want to add number labels to show the wells_count for that county. ggplot(data = wells_by_county, aes(x = county, y = wells_count)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label=wells_count), vjust=-0.25) Basic county plot In this case, we are just adding another layer, the geom_text(). It requires some additional aesthetics, like what label we want to use. The vjust= moves the numbers up a little. Change the number and see what happens. The last layer we want to add here is a Title layer. The function for labels is called labs() and it takes an argument of title = &quot;&quot; You can also change your x and y axis names, etc. ... + labs(title = &quot;Number of wells drilled by county&quot;) Congratulations! You made your first ggplot() chart. Not particularly revealing, but it does show that Travis County has WAY more wells than the other counties. Let’s see how those trends play out over time. 7.5 Wells per county over time Our next chart will be a line chart to show how the number of wells drilled has changed over time within each county. Again, it will help us to think about what we are after and then build our data frame to match. In this case, we want to plot the “number of wells” for each county, by year. That means we need columns for county, year and number of wells. To get that, we have to use group and summarize. Sometimes it helps to write out the steps of everything before you to do it. Start with the wells data frame. Filter to 2003 or later, because that’s when the system came online. Group by the county and year_drilled fields. Summarize to create a count the number of wells_drilled. Set all of the above to a new data frame, wells_county_year. Start a plot with the new data. Set x (horizontal) to be year_drilled and y (vertical) to be wells_drilled, and color to be the county. 7.5.1 Work up the data frame wells %&gt;% filter(year_drilled &gt;= 2003) %&gt;% group_by(county, year_drilled) %&gt;% summarise( wells_drilled = n() ) This gives you a table similar to this: county year_drilled wells_drilled Bastrop 2003 110 Bastrop 2004 99 Bastrop 2005 97 … … … Caldwell 2003 40 Caldwell 2004 32 Caldwell 2005 40 We call this long data, because each row contains a single observation, instead of wide data, which would have a column for each observation. Once you are have the data formatted, set it to fill a new data frame called wells_county_year. 7.5.2 Draw the plot Remember the formula for a basic plot: ggplot(&lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(aes(&lt;MAPPINGS&gt;)) and if all our mappings are the same, they can go into the ggplot function. ggplot(wells_county_year, aes(x = year_drilled, y = wells_drilled, color = county)) + geom_line() Wells drilled by county by year How easy would it be to add points for every year to make each data point stand out? 7.5.3 Your turn: Add layers Add a new layer geom_point() and see what happens Add a labels layer to add a title, like we did in the bar chart above. 7.5.4 Dates as numbers and the problems they cause There was one point during my work on this graphic when my x axis did not fall evenly on years, and I figured it was because the year_drilled field was a number and not a date. It’s possible to fix that by including the library(lubridate) and then mutating the year_drilled column like this: mutate( year_drilled = ymd(year_drilled, truncated=2L) ) %&gt;% 7.6 Your turn: Build a line chart Now, I’d like you to build a line chart that shows how the different kinds of wells drilled has changed over time. Here’s a major hint: It’s very much like the line chart you just built, but with different columns. You’ll need so start at creating a data frame with the correct data. 7.7 Review of ggplot Exploring with graphics are one of the more powerful features of working with R. It takes a bit to get used to the Grammar of Graphics and ggplot2 and it will be frustrating at first. But be assured it can do about anything once you learn how, and being able to fold in these charts with your thoughts and analysis in a repeatable way will make you a better data journalist. By design, every chart in ggplot starts with the same three things: data, a geometric coordinate system, and a mapping of the aesthetics, including the x and y values. ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) If your graphic is simple, there may be less verbose ways to write it as ggplot will assume your are passing it data first, and that aes() functions are for mapping. "],
["tidy.html", "Chapter 8 Tidy data", " Chapter 8 Tidy data About shaping data with tidyr. "],
["graphics2.html", "Chapter 9 Graphics II", " Chapter 9 Graphics II More on the ggplot now that we can tidy. "],
["census.html", "Chapter 10 Census 10.1 Resources", " Chapter 10 Census A mini project using census data. 10.1 Resources Census guide Sharon Machlis guide acs package (???) if News Nerdery is author of the [censusapi package] Baltimore Sun example. “sometimes i prefer the output of one over the other censusapi vs tidycensus, which is why i alternate. i also for some reason didn’t realize i could have used the R packages to download the SAIPE (poverty stats) data; in the repo I just downloaded the file from the site”. API key signup "],
["joins.html", "Chapter 11 Joins and merges", " Chapter 11 Joins and merges About joins, merges and the like. "],
["data.html", "Chapter 12 Data packages", " Chapter 12 Data packages About various data packages and such. "],
["maps.html", "Chapter 13 Maps", " Chapter 13 Maps About making maps. "],
["references.html", "References", " References Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 13.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 13.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 13.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 13.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). # download: [&quot;pdf&quot;, &quot;epub&quot;] # bookdown::pdf_book: # includes: # in_header: preamble.tex # latex_engine: xelatex # citation_package: natbib # keep_tex: yes # bookdown::epub_book: default "]
]
